\documentclass[a4paper,10pt]{article}

\bibliographystyle{plain}

\usepackage{tgpagella}
\usepackage{xspace}
\usepackage{todonotes}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{url}
\usepackage{mathrsfs}
\usepackage[pdftex, all]{xy}
\usepackage{hyperref}
\usepackage{cleveref}


\title{Second year report}

\author{Gabe Dijkstra}

\input{macros.tex}

\begin{document}

\maketitle

test~\cite{UFP2013}.

\section{Introduction}
\label{sec:introduction}

\section{Syntax of higher inductive types}
\label{sec:syntax}

If we define an ordinary inductive type, we start out by writing down
a list of constructors, \eg:
%
\begin{alignat*}{2}
  &\rlap{$\data\ T\ :\ \Type\ \where$} \\
  &&\ \ c_0  &:\ F_0\ T \to T \\
  &&\ \ c_1  &:\ F_1\ T \to T \\
  &&\ \      &\vdots \\
  &&\ \ c_k  &:\ F_k\ T \to T
\end{alignat*}
%
where $F_i : \Type \to \Type$. We require each $F_i$ to be a (strictly
positive) functor, in order to make sense of the computation rules of
the elimination operator. A constructor $c_i$ is then an algebra of
functor $F_i$ with carrier $T$. Equivalently, we can define an
inductive type with a single constructor:
%
\begin{alignat*}{2}
  &\rlap{$\data\ T\ :\ \Type\ \where$} \\
  &&\ \ c &:\ F\ T \to T 
\end{alignat*}
%
where $F\ X \ddefeq F_0\ X + F_1\ X + \hdots + F_k\ X$, so a single
functor is all we need to describe an \oit.

In the case of \hits, the situation is more involved. Consider for
example the circle data type:
%
\begin{alignat*}{2}
  &\rlap{$\data\ S^1\ :\ \Type\ \where$} \\
  &&\ \ \base     &:\ S^1 \\
  &&\ \ \loopcstr &:\ \base = \base
\end{alignat*}

There are two things that are different from our previous
situation. Firstly, the result type of $\loopcstr$ is not $S^1$, but a path
space of $S^1$: constructors are no longer algebras of functor, but a
kind of \emph{dialgebra}: the arguments as well as the result type of
a constructor may vary. Secondly, the $\loopcstr$ constructor refers to the
previous constructor $\base$.

The result type of a constructor can also depend on the value of its
arguments, as we see in the definition of propositional truncation as
a \hit:
%
\begin{alignat*}{2}
  &\rlap{$\data\ || A ||\ :\ \Type \where$} \\
  &&\ \ [\_]   &:\ A \to || A || \\
  &&\ \ \trunc &:\ (x\ y : || A ||) \to x = y
\end{alignat*}

Constructors of a \hit are \emph{dependent dialgebras}. In general, a
higher inductive type looks as follows:
%
\begin{alignat*}{5}
  &\rlap{$\data\ T\ :\ \Type\ \where$}& \\
  &&\ \ c_0    &: (x : F_0 T)                    &\to\ &G_0\ (T, x)& \\
  &&\ \ c_1    &: (x : F_1 (T,c_0))              &\to\ &G_1\ ((T, c_0), x)& \\
  &&\ \ c_2    &: (x : F_2 (T,c_0,c_1))          &\to\ &G_2\ ((T, c_0, c_1), x)& \\
  &&\ \        &\vdots &&\\
  &&\ \ c_{k+1} & : (x : F_k (T,c_0, \hdots, c_k) &\to\ &G_k\ ((T, c_0, \hdots, c_k), x)&
\end{alignat*}

We will refer to the $F_i$ functors as \emph{argument} functors and the
$G_i$ functors as \emph{target} functors. The types of the argument
functors are:
%
\begin{alignat*}{6}
&F_0     &\ :\ &\Type                &\ \to \Type& \\
&F_1     &\ :\ &\algcat{(F_0, G_0)}  &\ \to \Type& \\      
&F_2     &\ :\ &\algcat{(F_1, G_1)}  &\ \to \Type& \\      
&F_{k+1} &\ :\ &\algcat{(F_k, G_k)}  &\ \to \Type&
\end{alignat*}
%
where $\algcat{(F_0, G_0)}$ is the category whose objects are dependent
dialgebras $(X : \Type) \times (\theta : (x : F_0\ X) \to G_0\ (X,\ x))$. The category
$\algcat{(F_{i+1},G_{i+1})}$ has as objects: $(X : \algcat{(F_i,G_i)}) \times (\theta : (x :
F_{i+1}\ X) \to G_{i+1}\ (X, x)$. The target functors also take the value of
the arguments as an argument, so they have the following types:
%
\begin{alignat*}{6}
&G_0     &\ :\ &\int_{\Type} F_0                &\ \to \Type& \\
&G_1     &\ :\ &\int_{\algcat{(F_0, G_0)}} F_1  &\ \to \Type& \\      
&G_2     &\ :\ &\int_{\algcat{(F_1, G_1)}} F_2  &\ \to \Type& \\      
&G_{k+1} &\ :\ &\int_{\algcat{(F_k, G_k)}} F_{k+1}  &\ \to \Type&
\end{alignat*}

We see that the general shape of a constructor is a dependent dialgebra:
$$
c : (x : F\ X) \to G\ (X , x)
$$
where $\C : \catcat$, $F : \C \to \Type$ and
$G : \int_{\C} F \to \Type$, where $\C$ is either $\Type$ or some
category of dependent dialgebras, ``containing'' all the previous
constructors.

When describing \hits, we do not allow for any target functor $G$: it
must either return the type we are defining or a (possibly iterated)
path space of that type. A constructor of which the target is an
$n$-times iterated path space is called an \emph{$n$-constructor}. The
$0$-times iterated path space of a type $A$ is simply the type $A$
itself, hence ordinary constructors are \zeroconstructors. We call a
\hit an $n$-\hit if $n$ is the maximum iteration depth of its
constructors.

A \emph{\zeroconstructor} or \emph{point constructor} is a dialgebra:
$$
c : (x : F\ X) \to U\ X
$$
where $\C : \catcat$, $F : \C \to \Type$ and $U : \C \to Type$ its forgetful
functor.

A \emph{\oneconstructor} is a dependent dialgebra of which the target
functor returns a path space:
$$
  c : (x : F\ X) \to \Eq_0\ (X, x)
$$
where $\C : \catcat$, $F, U : \C \to \Type$, and $\Eq_0 : \int_{\C} F \to
\Type$ is the functor:
$$
  \Eq_0\ (X , x) \ddefeq (l_0\ x = r_0\ x)
$$
where $l_0,\ r_0 : F \to U$ are natural transformations.

For higher path constructors, we have to specify a tower of natural
transformations, specifying the end points at every level. To specify
an $(k+1)$-constructor, we need to give the natural transformations:
%
\begin{alignat*}{5}
  &l_0,\ r_0  &\ :\ &F \to U& \\
  &l_1,\ r_1  &\ : \ &1 \to \Eq_0& \\
  &l_2,\ r_2  &\ : \ &1 \to \Eq_1& \\
  &           &\vdots&& \\
  &l_k,\ r_k  &\ : \ &1 \to \Eq_{k-1}&
\end{alignat*}
%
where $\Eq_i\ (X, x) \ddefeq (l_i\ x = r_i\ x)$. $Eq_n$ is then the target
functor we are interested in.

Even when we consider only \zeroconstructors, the above scheme is more
general than the schemes that are usually considered when talking
about \oits: any constructor may refer to any previous
constructor, \eg:
%
\begin{alignat*}{5}
  &\rlap{$\data\ T\ :\ \Type\ \where$} \\
  &\ \ c_0 &\ :\ &T&\\
  &\ \ c_1 &\ :\ &c_0 = c_0 \to T&
\end{alignat*}
%
In fact, Agda even allows such definitions.

\section{Initiality and induction for \oits}
\label{sec:oits}

As mentioned in~\cref{sec:syntax}, an \oit is fully described by a
single endofunctor $F : \Type \to \Type$.

\todoi{introduce algebras and algebra morphisms?} 

\todoi{do more introduction of this section}

\subsection{Initiality}
\label{sec:oitinitiality}

One way to characterise inductive types is as the initial algebra of
the given endofunctor. An algebra is initial if there exists a unique
arrow to any algebra. In other words: for any algebra, the type of
morphisms between the the initial algebra and that algebra is
contractible:
%
\begin{defn}
  An algebra $\alg{X} : \algcat{F}$ is \emph{homotopy initial} if we
  have a proof of
  $(\alg{Y} : \algcat{F}) \to \iscontr{\algcat{F}(\alg{X}, \alg{Y})})$
\end{defn}
%
Note that being homotopy initial is a proposition.

\subsection{Induction principle}
\label{sec:oitinduction}

The induction principle of an inductive type $T$ gives us a method to
show that for a predicate $P : T \to \Type$, for all $x : T$, $P\ x$
holds. Intuitively we have to show for each constructor $c$ that if
$P$ holds for all $T$-subterms of $x$, then $P$ holds for $c x$. For
example, for the natural numbers, we have the induction operator:

\todoi{elim nat}

The induction operator also comes with computation rules:

\todoi{elim nat comp rules}

Generalising this to an arbitrary inductive type $T$ given by a
functor $F : \Type \to \Type$, we need to be able to state that a
predicate $P : T \to \Type$ holds for all $T$-subterms of $x : FT$. We
will do this by introducing a modality
$\Box_F : (A \to \Type) \to FA \to \Type$, which is defined by the
following equation, for $A : \Type$, $B : A \to \Type$:
$$
F (\Sigma\ A\ B) = \Sigma\ FA\ (\Box_{F} B)
$$
By singleton elimination we can then give the following definition of $\Box_{F}\ B$:
$$
\Box_{F}\ B\ x = (y : F (\Sigma\ A\ B)) \times (F\ \pi_1\ x = y)
$$
The induction principle for $T$ then becomes:

\todoi{elim T}

with computation rules:

\todoi{elim T comp rules and introduce $\actionsection{F}$?}

Usually $P$ is called the \emph{motive} of the induction and $m$ its
\emph{method}. One can also think of a motive along with a method as a
\emph{family} of algebras:

\begin{defn}
  An \emph{$F$-algebra family} over an algebra $(X,\theta)$, denoted
  $\Famover{\algcat{F}}{(X,\theta)}$, consists of:

  \begin{itemize}
  \item $P : X \to \Type$
  \item $m : (x : F\ X) \to \Box_F\ P\ x \to P\ (\theta\ x)$
  \end{itemize}
\end{defn}

In $\Type$, giving a family over a type $A : \Type$ is the same as
giving a function into $A$, \ie:
$$
(A \to \Type) = (B : \Type) \times (p : B \to A)
$$
In~\cref{sec:oitsectioninduction} we will show that giving a
family over an algebra $\alg{X} : \algcat{F}$ is the same as giving an
algebra morphism into $\alg{X}$:
$$
\Famover{\algcat{F}}{\alg{X}} = (\alg{Y} : \algcat{F}) \times \algcat{F}(\alg{Y},\alg{X})
$$

\subsection{Section principle}
\label{sec:oitsection}

Instead of showing directly that the induction principle is logically
equivalent to homotopy initiality, we introduce another principle that
is somewhere in between the type theoretic induction principle and the
categorical notion of initiality. In~\cref{sec:oitinduction}, the
induction principle for an inductive type $T$ gives us for every
algebra family $(P,m)$, a dependent function $(x : T) \to P\ x$
subject to certain computation rules. The section principle states
that every \emph{algebra fibration} has a \emph{section}.

\begin{defn}
  An \emph{$F$-algebra fibration} over an algebra $\alg{X}$ is an
  algebra $\alg{Y}$ along with an algebra morphism
  $\algcat{F}(\alg{Y},\alg{X})$. The type of $F$-algebra fibrations
  over $\alg{X}$ is denoted as $\fibover{\algcat{F}}{\alg{X}}$
\end{defn}

\begin{defn}
  An algebra $\alg{X}$ satisfies the \emph{section principle} if for
  every algebra fibration
  $\algfib{P} : \fibover{\algcat{F}}{\alg{X}}$, there exists a section
  $s : \algcat{F}(\alg{X},\alg{Y})$ of $p$, \ie
  $p \circ s = \Id{\alg{X}}$.
\end{defn}

Note that in order for this to be a complete definition, we have to
define composition of algebra morphisms and define the identity
morphisms. This will be done in~\cref{sec:oitalgcat}.

\subsection{Induction principle is logically equivalent to section principle}
\label{sec:oitsectioninduction}

\todoi{this, first think about approach} 

\subsection{Section principle is logically equivalent to initiality}
\label{sec:oitsectioninitiality}

We will first show that initiality implies the section principle.

\begin{prop}
  If $\alg{X} : \algcat{F}$ is initial, then every morphism
  $\algcat{F}(\alg{Y},\alg{X})$ admits a section.
\end{prop}

\begin{proof}
  Suppose $\alg{X} : \algcat{F}$ is initial, $\alg{Y} : \algcat{F}$
  and $p : \algcat{F}(\alg{Y},\alg{X})$. Since $\alg{X}$ is initial,
  there is a morphism $s : \algcat{F}(\alg{X},\alg{Y})$. Since
  $\alg{X}$ is initial, there is only one morphism
  $\algcat{F}(\alg{X},\alg{X})$, namely $\Id{\alg{X}}$, hence
  $p \circ s = \Id{\alg{X}}$, therefore $s$ is a section of $p$ and we
  are done.
\end{proof}

To prove the converse, we need to appeal to more of the category
structure of $\algcat{F}$.

\begin{prop}
  If $\alg{X} : \algcat{F}$ satisfies the section principle, then it
  is initial.
\end{prop}

\begin{proof}
  Let $\alg{X} : \algcat{F}$ be an algebra that satisfies the section
  principle, then we have to show that for any algebra
  $Y : \algcat{F}$ there exists a unique algebra morphism
  $f : \algcat{F}(\alg{X},\alg{Y})$. Given $\alg{X}$ and $\alg{Y}$, we
  can form the product of algebras $\alg{X} \times \alg{Y}$, which
  comes with projections
  $\pi_1 : \algcat{F}(\alg{X} \times \alg{Y}, \alg{X})$ and
  $\pi_2 : \algcat{F}(\alg{X} \times \alg{Y}, \alg{Y})$. Let
  $s : \algcat{F}(\alg{X},\alg{X} \times \alg{Y})$ be the section of
  $\pi_1$. We can then construct the $f$ as follows:
$$
\xymatrix{ &\alg{X} \ar[r]^-{s} &\alg{X} \times \alg{Y}
  \ar[r]^-{\pi_2} &\alg{Y} }
$$
Now we have to show that for any $g : \algcat{F}(\alg{X},\alg{Y})$,
$f = g$. This can be done by constructing the equaliser $\alg{E}$ of
$f$ and $g$:
$$
\xymatrix{ &\alg{E} \ar[r]^{e} &\alg{X} \ar@<-.5ex>[r]_-{g}
  \ar@<.5ex>[r]^-{f} &\alg{Y} }
$$
We get a section $s : \algcat{F}(\alg{X},\alg{E})$ of $e$, which then
shows that $f = g$:
$$
\xymatrix{
  &\alg{E} \ar[r]^{e} &\alg{X} \ar@<-.5ex>[r]_-{g} \ar@<.5ex>[r]^-{f} &\alg{Y} \\
  &\alg{X} \ar[u]^{s} \ar[ur]_{\Id{\alg{X}}} }
$$
\end{proof}

\subsection{Category of algebras}
\label{sec:oitalgcat}

When showing that the section principle implies initiality, we had to
use quite a bit of the category structure of $\algcat{F}$. First of
all for the definition of the section principle we need to have
composition and identity morphisms. Apart from that, we need to be
able to construct equalisers and have proofs of the identity laws and
associativity. As it turns out $\algcat{F}$ (unlike $\Type$) is not a
\emph{strict category}: it does not satisfy the category laws strictly
but only weakly.

In this section we will assume that $F$ is given as a container, which
means that it satisfies the functor laws strictly, simplifying the
equational reasoning.

\subsubsection{Identity morphisms}

Given an algebra $(X,\theta)$ we can construct the identity morphism as follows:
%
\begin{align*}
  &\Id{(X,\theta)} : \algcat{F}((X,\theta),(X,\theta)) \\
  &\Id{(X,\theta)} \ddefeq (\id{X} , \ido{(X,\theta)})
\end{align*}
%
where
%
\begin{align*}
  &\ido{(X,\theta)} : (x : FX) \to \id{X} (\theta x) = \theta (F \id{X} x) \\
  &\ido{(X,\theta)} x \ddefeq \\
  &\id{X} (\theta x) \\
  &\defeq \\
  &\theta x \\
  &\defeq \{ F is a strict functor \} \\
  &\theta (F \id{X} x)
\end{align*}
%
\subsubsection{Composition}

Given three algebras $(X,\theta), (Y,\rho), (Z,\zeta)$ and morphisms
$(g,g_0) : (Y,\rho) \to (Z,\zeta)$,
$(f,f_0) : (X,\theta) \to (Y,\rho)$, we need to construct a morphism
$(X,\theta) \to (Z,\zeta)$:
%
\begin{align*}
  &(g,g_0) \circ (f,f_0) : \algcat{F}((X,\theta),(Y,\rho)) \\
  &(g,g_0) \circ (f,f_0) \ddefeq (g \circ f , g_0 \circ_0 f_0)
\end{align*}
%
where
%
\begin{align*}
  &g_0 \circ_0 f_0 : (x : FX) \to (g \circ f) (\theta x)) = \zeta (F (g \circ f) x) \\
  &g_0 \circ_0 f_0 x \ddefeq \\
  &(g \circ f) (\theta x) \\
  &\defeq \{ asdf \} \\
  &g (f (\theta x)) \\
  &= \{ \ap g (f_0 x) \} \\
  &g (\rho (F f x)) \\
  &= \{ g_0 (F f x) \} \\
  &\zeta (F g (F f x)) \\
  &\defeq \{ F is a strict functor \} \\
  &\zeta (F (g \circ f) x
\end{align*}
%
Note that if $F$ is given as a container, it satisfies the functor
laws strictly, which simplifies the definition of algebra morphism
composition.

\subsubsection{Equality of algebra morphisms}

In order to prove the category laws, we need to know what the equality
of algebra morphisms looks like. Let $(X,\theta)$ and $(Y, \rho)$ be
algebras and $(f,f_0) ,(g, g_0) : \algcat{F}((X,\theta),(Y,\rho))$,
then, since we know that an equality of two dependent pairs is a
dependent pair of equalities and using function extensionality, we
get:
$$
((f,f_0) = (g,g_0)) = (p : f = g) \times (p_0 : (x : FX) \to f_0 = g_0 [ \lambda h . h (\theta x) = \rho (F h x) \downarrow p ])
$$
As we will see for the category laws, since $\Type$ is a strict
category hence the $p$ part of algebra morphism equalities will be
$\refl$ and $p_0$ will reduce to an non-dependent path. If $p$ is
non-trivial, we can still simplify the $p_0$ part. Giving $p_0$
amounts to giving the following square for every $x : FX$:
$$
\xymatrix{
f (\theta x) \ar@{-}[d]_{f_0 x} \ar@{-}[r]^{\ap (\lambda h . h (\theta x)) p}  &g (\theta x) \ar@{-}[d]^{g_0 x} \\
\rho (F f x) \ar@{-}[r]_{\ap (\lambda h . \rho (F h x)) p} &\rho (F g x) }
$$

\subsubsection{Identity laws}

Let $(f , f_0) : \algcat{F}((X,\theta),(Y,\rho))$ be an algebra
morphism. We need to show that
$\Id{(Y,\rho)} \circ (f , f_0) = (f , f_0) \circ \Id{(X,\theta)} =
(f,f_0)$.

Since $\Type$ satisfies the category laws strictly, we only need to
focus on $f_0 \circ_0 \ido{(X,\theta)}$, $\ido{(X,\theta)} \circ_0 f_0$
and $f_0$. For $x : FX$, we have:
%
\begin{align*}
  &f_0 \circ_0 \ido{(X,\theta)} x \\
  &\defeq \\
  &\ap f (\ido{(X,\theta)} x) \ct f_0 (F \id{X} x) \\
  &\defeq \{ F is a strict functor \} \\
  &\ap f (\ido{(X,\theta)} x) \ct f_0 x \\
  &\defeq \{ \ido{(X,\theta)} is trivial \} \\
  &\refl \ct f_0 x \\
  &= \\
  &f_0 x
\end{align*}
%
The proof of $\ido{(Y,\rho)} \circ_0 f_0 x = f_0 x$ goes in a similar
fashion. Whether the entire proof reduces to reflexivity depends on
how path composition is defined: if it is defined by induction on the
left argument, the left identity law holds strictly but the right
identity law does not, and vice versa. If path composition is defined
by induction on both arguments, then neither law holds strictly.

\subsubsection{Associativity}

Given four algebras $(X,\theta), (Y,\rho), (Z,\zeta), (W,\omega)$ and
morphisms $(h,h_0) : (Z,\zeta) \to (W,\omega)$,
$(g,g_0) : (Y,\rho) \to (Z,\zeta)$,
$(f,f_0) : (X,\theta) \to (Y,\rho)$, we need to show that:
$$
((h,h_0) \circ (g,g_0)) \circ (f,f_0) = (h,h_0) \circ ((g,g_0) \circ (f,f_0)) = 
$$
As with the identity laws, associativity holds strictly for the
underlying functions, so we need to show for every $x : FX$ that:
$$
(h_0 \circ_0 g_0) \circ_0 f_0 x = h_0 \circ (g_0 \circ_0 f_0) x
$$

\todoi{show horrendous proof}

\subsubsection{Products}

Given algebras $(X,\theta)$ and $(Y,\rho)$, we can define their
product $(X,\theta) \times (Y,\rho)$ as follows:
%
\begin{align*}
  &(X,\theta) \times (Y,\rho) : F-alg\\
  &(X,\theta) \times (Y,\rho) \ddefeq (X \times Y , \lambda x . (\theta (F \pi_1 x) , \rho (F \pi_2 x)))
\end{align*}
%
The projections $\pi_1$ and $\pi_2$ are then also strict algebra morphisms.

\subsubsection{Equalisers}

Given algebras $(X,\theta), (Y,\rho)$ and a parallel pair of morphisms
$(f,f_0),(g,g_0) : \algcat{F}((X,\theta),(Y,\rho))$, we need to find
an algebra $(E,\epsilon)$ along with morphism
$(e,e_0) : \algcat{F}((E,\epsilon),(X,\theta))$ such that the
following commutes:
$$
\xymatrix{ &(E,\epsilon) \ar[r]^{(e,e_0)} &(X,\theta) \ar@<-.5ex>[r]_-{(g,g_0)}
  \ar@<.5ex>[r]^-{(f,f_0)} &(Y,\rho) }
$$
We can $E$ to be the equaliser (in $\Type$) of $f$ and $g$, \ie:
$$
E \ddefeq (x : X) \times (f x = g x)
$$
and define $e : E \to X$ as the first projection: $e \ddefeq \pi_1$.
We define $p : e \circ f = e \circ g$ by function extensionality:
$p \ddefeq \funext \circ \pi_2$. We have to define an algebra
structure $\epsilon : FE \to E$ such that $e : E \to X$ becomes an
algebra morphism, \ie for all $x : FE$,
$\pi_1 (\epsilon x) = \theta (F \pi_1 x)$, so we only have to define
$\pi_2 (\epsilon x) : f (\theta (F e x)) = g (\theta (F e x))$. We
define $\pi_2 (\epsilon x)$ as the path:
%
\begin{align*}
  &f (\theta (F e x)) \\
  &= \{ f_0 (F e x) \} \\
  &\rho (F f (F e x)) \\
  &\defeq \{ F functor \} \\
  &\rho (F (f \circ e) x) \\
  &= \{ \ap (\lambda h . \rho (F h x)) p \} \\
  &\rho (F (g \circ e) x) \\
  &\defeq \{ F functor \} \\
  &\rho (F g (F e x)) \\
  &= \{ g_0 (F e x) ^{-1} \} \\
  &g (\theta (F e x))
\end{align*}
%
Note that by construction, $e_0 x \defeq \refl$. We still have to show
that composing $(e,e_0)$ with $(f,f_0)$ or $(g,g_0)$ yields the same
results, so we have to give:
$$
p : f \circ e = g \circ e
$$
and for all $x : FE$ the square:
$$
\xymatrix{
f (e (\epsilon x)) 
  \ar@{-}[r]^{\ap (\lambda h . h (\epsilon x)) p} 
  \ar@{-}[d]_{f_0 (F e x)}  
&g (e (\epsilon x)) 
  \ar@{-}[d]^{g_0 (F e x)}
\\
\rho (F (f \circ e) x)
  \ar@{-}[r]_{\ap (\lambda h . \rho (F h x)) p}
&\rho (F (g \circ e) x)}
$$

\todoi{this proof}

We do not need to show that our equaliser satisfies the universal
property as this is not used by the proof that section induction
implies initiality.

\section{Initiality and induction for \hits}
\label{sec:hits}

In this section we will attempt to generalise the previous
constructions to \hits. We will start out with the most general
approach and see where we run into (usually coherence) problems and
will impose restrictions to make things more tractable.

We have seen that a \hit can be described as a sequence of pairs of
functors, where the domain of the functors depends on the category of
algebras of all the previous constructors. Since we are only concerned
with establishing an induction principle, defining the category of
algebras and showing that the induction principle and initiality
coincide, we do not immediately need to restrict ourselves to strictly
positive functors. We will also not put restrictions on the target
functors a priori to see how far we can get without them.

We can formalise such a specification of a \hit as the
following inductive-recursive definition:
%
\begin{align*}
  &\Spec : \Type \\
  &\Alg : Spec \to \Cat \\
  \\
  &\data \Spec \where \\
  &\epsilon : \Spec \\
  &\_,\_ : (s : \Spec) \to \Constr (\Alg s) \to \Spec    
  \\
  &\Alg \epsilon \ddefeq \Type\\
  &\Alg (s , c) \ddefeq \extend (\Alg s) c
\end{align*}
%
where
%
\begin{align*}
  &\Constr \C \ddefeq (F : \C \To \Type) \times (G : \int \C F \To \Type)
\end{align*}
%
and
%
\begin{align*}
  &\extend : (\C : \Cat) \to \Constr \C \to \Cat
\end{align*}
%
and $\To : \Cat \to \Cat \to \Type$ is the type of functors. This
definition makes it clear how every constructor defined depends on all
the previous constructors.

The definition of $\extend$ depends on $\Cat$: if we add more
coherence laws to the definition of $\Cat$, we have to adjust
$\extend$ accordingly, which usually also means putting more coherence
laws in the definition of functor.

\todoi{show problems with identity and all that, we want functors to be strict}

\section{Initiality and induction for \onehits}
\label{sec:onehits}

Instead of considering the most general case, we will restrict
ourselves to \onehits of the form:
%
\begin{alignat*}{2}
  &\rlap{$\data\ T\ :\ \Type\ \where$} \\
  &&\ \ c_0  &:\ F_0\ T \to T \\
  &&\ \ c_1  &:\ (x : F_1\ T) \to c_0 * (l\ x) = c_0 * (r\ x)
\end{alignat*}
%
where:
\begin{itemize}
\item $F_0, F_1 : \Type \to \Type$ are (strict) functors, given as containers
\item $l r : F_1 \to F_0 *$ are (strict) natural transformations, given as container morphisms
\end{itemize}

\todoi{show that this is less general than the ordinary $(0,1)$-HIT, but straightforward restriction}

\todoi{explain $F_0 *$ free monad}

\subsection{Initiality}

\subsection{Induction principle}

\subsection{Section principle}

\subsection{Induction principle is logically equivalent to section principle}

\subsection{Section principle is logically equivalent to initiality}

\subsection{Category of algebras}



\bibliography{second-year-report}

\end{document}

