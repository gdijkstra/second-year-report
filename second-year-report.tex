\documentclass[a4paper,10pt]{report}

\bibliographystyle{plain}

\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{xspace}
\usepackage{todonotes}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{url}
\usepackage{mathrsfs}
\usepackage[pdftex, all]{xy}

\title{Second year report}

\author{Gabe Dijkstra}

\input{macros.tex}

\begin{document}

\maketitle

\chapter{Introduction}
\label{sec:introduction}

One of the insights of \hott is that we can view a type as a
topological space (up to homotopy) and equalities between elements of
the type as paths. For every inhabitant (or point) $a$ in a type $A$,
we have the equality $\refl : a = a$. This (trivial) equality can be
thought of as the constant path from $a$ to $a$. Since equality in
\mltt is defined as an inductive type, it also comes with an
elimination principle. This principle allows us to show that equality
gives us an equivalence relation on a type. For inhabitants
$x, y, z : A$ and equalities $p : x = y$, $q : y = z$, we can define
an equality $p \ct q : x = z$ (transitivity) and we can define an
equality $p^{-1} : y = x$ (symmetry). We can also consider equalities
\emph{between} equalities, \eg we can prove that transitivity,
symmetry along with $\refl$ satisfy the groupoid
laws~\cite{Hofmann1998}. There is no need to stop there, we can also
consider equalities between equalities between equalities, ad
infinitum: a type along with its equality types forms a weak
$\omega$-groupoid~\cite{VanDenBerg2008}.

This then raises the question what kind of homotopical structure we
get in the types we know. For the usual types, such as the natural
numbers and the booleans, the structure is rather trivial: two
elements of are either equal, connected by a unique path ($\refl$), or
they are not equal, \ie not connected by a path. Types like these
satisfy \emph{\uip}. In topology a space with this property is called
a \emph{discrete} space. Types that satisfy \uip are usually referred
to as \emph{h-sets} or simply \emph{sets}.

If we talk about the universe of types $\Type$, we would like that
equality of elements in this type coincides with isomorphism of
types. In \hott, one typically assumes the \emph{univalence} axiom for
a universe of types, which tells us, for any types $A$ and $B$:
$$
(A \simeq B) = (A = B)
$$
Universes that satisfy univalence, also called \emph{univalent
  universes} often do not satisfy \uip, \eg assuming $\Type$ is
univalent, we have two distinct equalities on $Bool : \Type$: $\id{}$
(or $\refl$) and $\boolnot$. Identifying these two equalities would
allow us to prove $\true = \false$.

Instead of looking at the homotopical structure of types we are
already familiar with, we can do the converse and look at the
geometric examples from homotopy theory, such as spheres and tori. The
question then becomes how we represent such objects in a type
theoretic way. \Hits have been introduced to provide an answer to this
question.

One example of such a space is the circle: a path going around the
circle two times is not a path we can continuously deform into a path
that goes around the circle one time. A \hit that corresponds to the
circle is:
%
\begin{alignat*}{2}
  &\rlap{$\data\ S^1\ :\ \Type\ \where$} \\
  &&\ \ \base     &:\ S^1 \\
  &&\ \ \loopcstr &:\ \base = \base
\end{alignat*}
%
The circle is defined as a type with a point $\base$ and a
(non-trivial) loop $\loopcstr$. $\loopcstr$ is called a \emph{higher}
constructor, as it does not map into the type $S^1$, but one of its
equality types. $S^1$ comes with a recursion principle or
non-dependent eliminator:
$$
\rec : (A : \Type) (b : A) (l : b = b) \to S^1 \to A
$$
which comes with the following computation rules, given $A : \Type$,
$b : A$ and $l : b = b$:
%
\begin{align*}
&\rec\mbox{-}\beta_0 : \rec\ A\ b\ l\ \base = b \\
&\rec\mbox{-}\beta_1 : \ap\ \rec\ \loopcstr = l
\end{align*}
%
The recursion principle for $S^1$ tells us that in order to map out of
$S^1$, we need to what we want to map the constructor $\base$ to and
also where we want to mape the \emph{path constructor} $\loopcstr$
to. Just as the constructor $\loopcstr$ refers to a previous
constructor, the data for the recursion principle has the same
dependency. This means that we cannot blindly reorder the constructors
of $S^1$, nor the data for the recursion principle.

The induction principle or dependent eliminator of $S^1$ is as
follows:
$$
\ind : (P : S^1 \to \Type) (b : P\ \base) (l : b = b [ P \downarrow \loopcstr ]) \to (x : S^1) \to P\ x
$$
Note that for $l$ we now have to give a dependent path over
$\loopcstr$.

For \oits, it is usually the case that the computation rules for the
elimination principles hold definitionally. In this note we want to
talk about the theory of \hits in type theory itself and as such we do
not have a way to talk about definitional equalities, hence the
computation rules we talk about only hold by propositional equality.

We can also have constructors that map into an equality type of an
equality of the type we are defining, one example being the torus:
%
\begin{alignat*}{2}
  &\rlap{$\data\ T^2\ :\ \Type\ \where$} \\
  &&\ \ \base     &:\ T^2 \\
  &&\ \ p         &:\ \base = \base \\
  &&\ \ q         &:\ \base = \base \\
  &&\ \ s         &:\ p \ct q = q \ct p
\end{alignat*}
%
The constructor $s$ maps into an equality type not of $T^2$, but
$\base = \base$. A constructor such as $\base$ is referred to as a
\emph{point constructor} or \emph{\zeroconstructor}, as they construct
points, but do not introduce any new non-trivial paths
themselves. Constructors such as $p$ and $q$ are called
\emph{\oneconstructors} and $s$ a \emph{\nconstructor{2}}. For
$n > 0$, \nconstructors{n} are also referred to as \emph{path
  constructors}.

\section{\Hits versus quotients}
\label{sec:quotients}

Another example of a \hit is the quotient of a type $A$ by a relation
$~ : A \to A \to \Type$:
\begin{alignat*}{2}
  &\rlap{$\data\ A/\sim\ :\ \Type\ \where$} \\
  &&\ \ [\_]  &:\ A \to A/\sim \\
  &&\ \ \quot &:\ (x\ y : A) \to x \sim y \to [ x ] = [ y ] \\
  &&\ \ \uipc  &:\ (x\ y : A/\sim) (p\ q : x = y) \to p = q
\end{alignat*}
%
Note that we have to add $\uipc$ as a constructor to make sure that the
result is a set. Without it, we may get non-trivial equalities even
though we $A$ might be a set and $~$ is propositional everywhere. An
example of this is taking $A$ to be the unit type and ``quotienting''
it by the trivial, relation, \ie $x ~ y = \unitty$ for all
$x\ y : \unitty$. Without the $\uipc$ constructor, $A/~$ will be
equivalent to the circle.

It is clear that we can implement quotient types using \hits. The
other way around does not hold for different reasons. When we talk
about quotient types, we usually talk about quotienting a \emph{set}
by a propositional, relation, and do not think about them as a way of
introducing types with non-trivial (higher) equalities. However, even
if we restrict ourselves to sets, \hits are more general than
quotients. An example where this difference shows up is the type of
infinitely branching trees up to permutation:
%
\begin{alignat*}{2}
  &\rlap{$\data\ \Tree\ :\ \Type\ \where$} \\
  &&\ \ l     &:\ \Tree \\
  &&\ \ n     &:\ (Nat \to \Tree) \to \Tree \\
  &&\ \ q     &:(f\ g : \Nat \to \Tree) (p : \Nat = \Nat) \to ((x : \Nat) \to f\ x = g\ (\coe\ p\ x)) \to n\ f = n\ g \\
  &&\ \ \uipc &:(x\ y : Tree) (p\ q : x = y) \to p = q
\end{alignat*}
%
We put in the constructor $\uipc$ since we are only interested in the points here.

We could try to emulate this \hit using quotients by first defining
infinitely branching trees (without the permutations) and then
quotienting this type by the permutation relation:
%
\begin{alignat*}{2}
  &\rlap{$\data\ \Pretree\ :\ \Type\ \where$} \\
  &&\ \ l     &:\ \Pretree \\
  &&\ \ n     &:\ (Nat \to \Pretree) \to \Pretree \\
\end{alignat*}
%
\begin{align*}
  &\sim : \Pretree \to \Pretree \to \Type \\
  &l \sim l \defeq \top \\
  &n\ f \sim n\ g \defeq (p : \Nat = \Nat) \times ((x : Nat) \to f\ x ~ g\ (\coe\ p\ x)) \\
  &l \sim n\ g \defeq \bot \\
  &n\ f \sim l \defeq \bot
\end{align*}
%
If we now want to lift the node constructor of $\Pretree$ to the
quotient $\Pretree/\sim$, we run into trouble: we want to define:
$$
n' : (\Nat \to \Pretree/\sim) \to \Pretree/\sim
$$
It seems that we need some sort of choice principle to make this
work. The important difference between the quotient approach and the
\hit approach is that with the latter the ``quotienting'' is done ``at
the same time'' as the induction.

\section{Inductive-inductive types}
\label{sec:inductiveinductive}

In the definitions of the circle $S^1$ and the torus $T^2$ we saw
(path) constructors that referred to previous constructors. Another
class of inductive types where this occurs are inductive-inductive
types~\cite{Altenkirch2011}. Inductive-inductive definitions can
describe families $A : \Type$, $B : A \to \Type$ where the
constructors of $A$ may refer to $B$ and $B$ may refer to $A$, as well
as \emph{constructors} of $A$. An example of an inductive-inductive
type is the syntax of (dependent) types and contexts:
%
\begin{alignat*}{2}
  &\rlap{$\data\ \Ctx\ :\ \Type\ \where$} \\
  &&\ \ \epsilon &:\ \Ctx \\
  &&\ \ \snoc    &:\ (\Gamma : \Ctx) \to \sigma : \Ty\ \Gamma \to \Ctx
\end{alignat*}
%
\begin{alignat*}{2}
  &\rlap{$\data\ \Ty\ :\ \Ctx \to \Type\ \where$} \\
  &&\ \ \unitty &:\ \Ctx \\
  &&\ \ \Pi     &:\ (\Gamma : \Ctx) (\sigma : \Ty\ \Gamma) (\tau : \Ty (\snoc \Gamma \sigma)) \to \Ty \Gamma
\end{alignat*}
%
Here we see the dependence on \emph{constructors} of $\Ctx$ in the
arguments of the constructor $\Pi$.

\section{Theory of \hits}
\label{sec:theoryhits}

As of yet, there is no formal description of what constitutes a \hit
and as such formally proving properties about them in general is
impossible. However, there are several somewhat formal statements
about \hits that can be made. Once we have a theory of \hits, these
are the sort of statements we ought to be able to prove.

\subsection{Reordering of constructors}

In the case of \oits, we can permute the order of constructors in our
definitions, \ie we know that the following describe equivalent types:
%
\begin{alignat*}{2}
  &\rlap{$\data\ \Nat\ :\ \Type\ \where$} \\
  &&\ \ \zero &:\ \Nat \\
  &&\ \ \suc  &:\ \Nat \to \Nat
\end{alignat*}
%
\begin{alignat*}{2}
  &\rlap{$\data\ \Nat \prime\ :\ \Type\ \where$} \\
  &&\ \ \suc  &:\ \Nat \prime \to \Nat \prime \\
  &&\ \ \zero &:\ \Nat \prime
\end{alignat*}

Similarly, we expect the following to be equivalent as well:
%
\begin{alignat*}{2}
  &\rlap{$\data\ T^2\ :\ \Type\ \where$} \\
  &&\ \ \base     &:\ T^2 \\
  &&\ \ p         &:\ \base = \base \\
  &&\ \ q         &:\ \base = \base \\
  &&\ \ s         &:\ p \ct q = q \ct p
\end{alignat*}
%
\begin{alignat*}{2}
  &\rlap{$\data\ T^2 \prime\ :\ \Type\ \where$} \\
  &&\ \ \base     &:\ T^2 \prime \\
  &&\ \ q         &:\ \base = \base \\
  &&\ \ p         &:\ \base = \base \\
  &&\ \ s         &:\ p \ct q = q \ct p
\end{alignat*}

With \hits there are permutations that do not make sense:
\begin{alignat*}{2}
  &\rlap{$\data\ \toruswrong\ :\ \Type\ \where$} \\
  &&\ \ s         &:\ p \ct q = q \ct p \\
  &&\ \ q         &:\ \base = \base \\
  &&\ \ p         &:\ \base = \base \\
  &&\ \ \base     &:\ \toruswrong
\end{alignat*}
When changing the position of a constructor, we cannot put it before
any constructor on which it depends.

\subsection{Hub-spokes reduction}

In the inductive definition of the torus $T^2$, there was the \twoconstructor:
$$
s : p \ct q = q \ct p
$$
which gives us a \emph{higher} path. As it turns out, such a
\twoconstructor can be represented by a \zeroconstructor (hub)
and a \oneconstructor (spokes):
%
\begin{align*}
&h : T^2 \\
&s' : (x : S^1) \to f\ x = h
\end{align*}
%
where $f : S^1 \to T^2$ is defined using the recursion principle of
$S^1$ with:
%
\begin{align*}
  &f\ \base \ddefeq \base \\
  &\ap\ f\ \loopcstr \ddefeq p \ct q \ct (q \ct p)^{-1}
\end{align*}
%
In this special case, one can show that the resulting type is
equivalent to the original $T^2$. Intuitively, the hub-spokes
construction replaces a path between paths with a hub together with a
path from every point on the ``boundary'' formed by the two original
paths being connected, to the hub point.

For \nconstructors{n} where $n > 2$, the construction can be iterated,
showing that we only need \zeroconstructors and
\oneconstructors. However, since we lack a formal definition of what
constitutes a \hit, we cannot prove this formally.

\subsection{Non-recursive \hits}

From the previous section we have seen that we only need
\zeroconstructors and \oneconstructors. In some cases it seems we can
also simplify the path constructors themselves. Consider the
propositional truncation \hit of a type $A$:
%
\begin{alignat*}{2}
  &\rlap{$\data\ || A ||\ :\ \Type\ \where$} \\
  &&\ \ [\_]   &:\ A \to || A || \\
  &&\ \ \trunc &:\ (x\ y : || A ||) \to x = y
\end{alignat*}
%
The constructor $\trunc$ is \emph{recursive} in that its arguments
refer to $|| A ||$ itself. We can replace $\trunc$ with a
non-recursive constructor, arriving at the following definition:
%
\begin{alignat*}{2}
  &\rlap{$\data\ \{ A \}\ :\ \Type\ \where$} \\
  &&\ \ [\_]   &:\ A \to \{ A \} \\
  &&\ \ \trunc &:\ (x\ y : A) \to \{ x \} = \{ y \}
\end{alignat*}
%
In general we do not have $|| A || = \{ A \}$, \eg when
$|| \unitty || = \unitty$, but $\{ \unitty \} = S^1$. We can consider
the cochain we get by applying $[\_]$ iteratively, starting from $A$:
$$
A \to \{ A \} \to \{ \{ A \} \} \to \{ \{ \{ A \} \} \} \to \hdots
$$
It turns out that taking the colimit of this cochain is equivalent to
$|| A ||$~\cite{VanDoorn2015}. Sequential colimits such as the above
are also examples of \hits:
%
A \emph{sequence} of types is a family $A : \Nat \to \Type$ along with
a family of functions $f : (n : \Nat) \to A\ n \to A\ (\suc\ n)$. The
sequential colimit of this sequence is given by the following \hit:
%
\begin{alignat*}{2}
  &\rlap{$\data\ A_\infty :\ \Type\ \where$} \\
  &&\ \ i : (n : \Nat) \to A\ n \to A\ (\suc\ n) \\
  &&\ \ g : (n : \Nat) \to (a : A\ n) \to i\ n\ a = i\ (\suc n)\ (f\ n\ a)
\end{alignat*}
%
We conjecture that there is a class of \hits with recursive path
constructors, such as propositional truncation, that can be
implemented as a colimit of a sequence of types given as \hits without
recursive path constructors, similar to the construction above.

\section{Categories in type theory}
\label{sec:catintt}

As we will be talking about categorical concepts in type theory in
this report, we have to elucidate what we mean when we say \eg
``category''. We can start by saying that a category $\C$ consists of:
%
\begin{itemize}
\item a type of objects: $\obj : \Type$
\item a type of morphisms: $\Hom : \obj \to \obj \to \Type$
\end{itemize}
%
Traditionally, the definition of a category has for each pair of
objects a \emph{set} of objects, whereas here we have a $\Type$. We
have seen that types are weak $\omega$-groupoids and therefore need
not be sets, \ie satisfy \uip. We can restrict the type of $\Hom$ to
only give us types that satisfy \uip. Doing so allows us to formalise
basic category theory in type theory~\cite{Ahrens2015}.

Since we want to talk about types and not just sets, such an approach
is not sufficient for us. However, if we have hom-types instead of
hom-sets, we should require the category laws to satisfy coherence
conditions, \eg the associator $\assoc$ should satisfy the usual
pentagon condition. The witness of the pentagon condition itself also
has to adhere to coherence conditions, and so on. Luckily, for $\Type$
itself this is not much of an issue, as the category laws hold
strictly. We will see that for the category of algebras $\algcat{F}$
of an endofunctor $F : \Type \to \Type$ is not a strict functor, so
there we cannot avoid talking about coherence.

The notion of \omegacat makes it precise what coherence conditions we
need. Defining what a \omegacat is exactly is requires the machinery
of simplicial simplicial sets (or bisimplicial sets). One could
replace bisimplicial sets with simplicial \emph{types}, but giving a
definition of simplicial types in type theory itself is
problematic. In order to do so, it seems one has to extend the theory
to be able to talk about strict equalities inside the theory. Instead
of giving a definition of \omegacats, we will deal with coherence
lazily: we will prove the appropriate conditions when we need them. We
will see that we are able to get some results with considering a
finite amount of coherence laws.

Since we are working internally, limit and colimit constructions yield
\emph{homotopy} limits and \emph{homotopy} colimits~\cite{Avigad2015}:
the constructions are up to propositional equality. When we talk about
initial algebras internally, these objects also correspond to
\emph{homotopy} initial algebras~\cite{Awodey2012}. We will usually
drop the ``homotopy'' prefix for readability purposes.

\section{Overview}
\label{sec:overview}

In~\cref{sec:syntax} we will introduce the syntax of \hits and
describe how they differ from \oits. In~\cref{sec:oits} we will show
how for \oits, being an initial algebra and satisfying the induction
principle coincide. In~\cref{sec:hits} we attempt to generalise this
construction to \hits and note which things work and what is
problematic. \Cref{sec:gencontainers} introduces the concept of
\emph{generalised containers}, which generalises the notion of
container or strictly positive functor from functors $\Type \to \Type$
to functors $\C \to \Type$ for any category
$\C$. In~\cref{sec:onehits} we consider a restricted scheme of \hits
in order to limit the coherence issues and work towards showing that
initiality and induction coincide. The last chapter,
\cref{sec:outline}, gives a thesis outline.

\section{Formalisation}
\label{sec:formalisation}

The goal of this project is to have a theory of \hits that we can
formalise in type theory. As such, many of the results in this report
have been formalised in Agda~\cite{Norell2009}:
\url{https://github.com/gdijkstra/homotopy-initiality/tree/general-approach}.

\chapter{Syntax of \hits}
\label{sec:syntax}

If we define an \oit, we start out by writing down
a list of constructors, \eg:
%
\begin{alignat*}{2}
  &\rlap{$\data\ T\ :\ \Type\ \where$} \\
  &&\ \ c_0  &:\ F_0\ T \to T \\
  &&\ \ c_1  &:\ F_1\ T \to T \\
  &&\ \      &\vdots \\
  &&\ \ c_k  &:\ F_k\ T \to T
\end{alignat*}
%
where $F_i : \Type \to \Type$. We require each $F_i$ to be a (strictly
positive) functor, in order to make sense of the computation rules of
the elimination operator. A constructor $c_i$ is then an algebra of
functor $F_i$ with carrier $T$. Equivalently, we can define an
inductive type with a single constructor:
%
\begin{alignat*}{2}
  &\rlap{$\data\ T\ :\ \Type\ \where$} \\
  &&\ \ c &:\ F\ T \to T 
\end{alignat*}
%
where $F\ X \ddefeq F_0\ X + F_1\ X + \hdots + F_k\ X$, so a single
functor is all we need to describe an \oit.

In the case of \hits, the situation is more involved. Consider for
example the circle data type:
%
\begin{alignat*}{2}
  &\rlap{$\data\ S^1\ :\ \Type\ \where$} \\
  &&\ \ \base     &:\ S^1 \\
  &&\ \ \loopcstr &:\ \base = \base
\end{alignat*}

There are two things that are different from our previous
situation. Firstly, the result type of $\loopcstr$ is not $S^1$, but a path
space of $S^1$: constructors are no longer algebras of functor, but a
kind of \emph{dialgebra}: the arguments as well as the result type of
a constructor may vary. Secondly, the $\loopcstr$ constructor refers to the
previous constructor $\base$.

The result type of a constructor can also depend on the value of its
arguments, as we see in the definition of propositional truncation as
a \hit:
%
\begin{alignat*}{2}
  &\rlap{$\data\ || A ||\ :\ \Type\ \where$} \\
  &&\ \ [\_]   &:\ A \to || A || \\
  &&\ \ \trunc &:\ (x\ y : || A ||) \to x = y
\end{alignat*}

Constructors of a \hit are \emph{dependent dialgebras}. In general, a
\hit looks as follows:
%
\begin{alignat*}{5}
  &\rlap{$\data\ T\ :\ \Type\ \where$}& \\
  &&\ \ c_0    &: (x : F_0 T)                    &\to\ &G_0\ (T, x)& \\
  &&\ \ c_1    &: (x : F_1 (T,c_0))              &\to\ &G_1\ ((T, c_0), x)& \\
  &&\ \ c_2    &: (x : F_2 (T,c_0,c_1))          &\to\ &G_2\ ((T, c_0, c_1), x)& \\
  &&\ \        &\vdots &&&\\
  &&\ \ c_{k+1} & : (x : F_k (T,c_0, \hdots, c_k)) &\to\ &G_k\ ((T, c_0, \hdots, c_k), x)&
\end{alignat*}

We will, refer to the $F_i$ functors as \emph{argument} functors and the
$G_i$ functors as \emph{target} functors. The types of the argument
functors are:
%
\begin{alignat*}{6}
&F_0     &\ :\ &\Type                &\ \to \Type& \\
&F_1     &\ :\ &\algcat{(F_0, G_0)}  &\ \to \Type& \\      
&F_2     &\ :\ &\algcat{(F_1, G_1)}  &\ \to \Type& \\      
&F_{k+1} &\ :\ &\algcat{(F_k, G_k)}  &\ \to \Type&
\end{alignat*}
%
where $\algcat{(F_0, G_0)}$ is the category whose objects are dependent
dialgebras $(X : \Type) \times (\theta : (x : F_0\ X) \to G_0\ (X,\ x))$. The category
$\algcat{(F_{i+1},G_{i+1})}$ has as objects: $(X : \algcat{(F_i,G_i)}) \times (\theta : (x :
F_{i+1}\ X) \to G_{i+1}\ (X, x)$. The target functors also take the value of
the arguments as an argument, so they have the following types:
%
\begin{alignat*}{6}
&G_0     &\ :\ &\int_{\Type} F_0                &\ \to \Type& \\
&G_1     &\ :\ &\int_{\algcat{(F_0, G_0)}} F_1  &\ \to \Type& \\      
&G_2     &\ :\ &\int_{\algcat{(F_1, G_1)}} F_2  &\ \to \Type& \\      
&G_{k+1} &\ :\ &\int_{\algcat{(F_k, G_k)}} F_{k+1}  &\ \to \Type&
\end{alignat*}

We see that the general shape of a constructor is a dependent dialgebra:
$$
c : (x : F\ X) \to G\ (X , x)
$$
where $\C : \catcat$, $F : \C \to \Type$ and
$G : \int_{\C} F \to \Type$, where $\C$ is either $\Type$ or some
category of dependent dialgebras, ``containing'' all the previous
constructors.

When describing \hits, we do not allow for any target functor $G$: it
must either return the type we are defining or a (possibly iterated)
path space of that type. A constructor of which the target is an
$n$-times iterated path space is called an \emph{$n$-constructor}. The
$0$-times iterated path space of a type $A$ is simply the type $A$
itself, hence ordinary constructors are \zeroconstructors. We call a
\hit an $n$-\hit if $n$ is the maximum iteration depth of its
constructors.

A \emph{\zeroconstructor} or \emph{point constructor} is a dialgebra:
$$
c : (x : F\ X) \to U\ X
$$
where $\C : \catcat$, $F : \C \to \Type$ and $U : \C \to Type$ its forgetful
functor.

A \emph{\oneconstructor} is a dependent dialgebra of which the target
functor returns a path space:
$$
  c : (x : F\ X) \to \Eq_0\ (X, x)
$$
where $\C : \catcat$, $F, U : \C \to \Type$, and $\Eq_0 : \int_{\C} F \to
\Type$ is the functor:
$$
  \Eq_0\ (X , x) \ddefeq (l_0\ x = r_0\ x)
$$
where $l_0,\ r_0 : F \to U$ are natural transformations.

For higher path constructors, we have to specify a tower of natural
transformations, specifying the end points at every level. To specify
an $(k+1)$-constructor, we need to give the natural transformations:
%
\begin{alignat*}{5}
  &l_0,\ r_0  &\ :\ &F \to U& \\
  &l_1,\ r_1  &\ : \ &1 \to \Eq_0& \\
  &l_2,\ r_2  &\ : \ &1 \to \Eq_1& \\
  &           &\vdots&& \\
  &l_k,\ r_k  &\ : \ &1 \to \Eq_{k-1}&
\end{alignat*}
%
where $\Eq_i\ (X, x) \ddefeq (l_i\ x = r_i\ x)$. $Eq_n$ is then the target
functor we are interested in.

\section{\nhits{0}}
\label{sec:zerohits}

Even when we consider only \zeroconstructors, the above scheme is more
general than the schemes that are usually considered when talking
about \oits: any constructor may refer to any previous
constructor, \eg:
%
\begin{alignat*}{5}
  &\rlap{$\data\ T\ :\ \Type\ \where$} \\
  &\ \ c_0 &\ :\ &T&\\
  &\ \ c_1 &\ :\ &c_0 = c_0 \to T&
\end{alignat*}
%
In fact, Agda even allows such definitions, although the above example
is not particularly useful.

In the general scheme presented earlier, the constructors map into the
type $T$ itself or its (iterated) path spaces. Lifting this
restriction to map into a collection of types instead allows us to
describe inductive-inductive types using the
scheme~\cite{Capriotti2014}.

\chapter{Initiality and induction for \oits}
\label{sec:oits}

In this section we will, recap some of the basic theory of \oits: we
will give its induction principle and explain the initial algebra
characterisation and how these two characterisations coincide. This
section provides an outline for how to approach the theory of \hits.

We will first explain how an \oit is specified and what its
introduction rules are in~\cref{sec:oitspec}.
In~\cref{sec:oitinitiality} we will define the category of algebras
and define initiality and in~\cref{sec:oitinduction} the induction
principle is defined. Instead of showing directly that initiality and
induction are equivalent, we formulate the \emph{section principle}
which is ``in between'' the two, in~\cref{sec:oitsection}. We will
first show that this principle is logically equivalent to the
induction principle in~\cref{sec:oitsectioninduction}. The section
principle is also logically equivalent to initiality, given by a
purely categorical proof in~\cref{sec:oitsectioninitiality}. The
categorical structure of the algebras needed for this proof is given
in~\cref{sec:oitalgcat}. In~\cref{sec:oitfreemonad} we conclude with
some remarks on free monads and their relation to \oits.

\section{Specification}
\label{sec:oitspec}
Specifying an \oit is done by giving an endofunctor
$F : \Type \to \Type$. We will assume this functor to be given as a
container~\cite{Abbott2005}, which ensures that it is strictly
positive. Since we are not primarily interested in the existence of
the inductive types, we do not need this particular
restriction. Containers do give rise to functors that satisfy the
functor laws strictly, which makes the equational, reasoning a lot more
convenient for us.

A functor $F$ defines an inductive type $T$ with type formation rule:
$$
\frac{}{T : \Type}
$$
and an introduction rule, or constructor:
$$
\frac{x : FT}{c\ x : T}
$$
Its elimination rules can either be stated as requiring $T$ to be
initial (\cref{sec:oitinitiality}) or as $T$ being endowed with an
induction principle (\cref{sec:oitinduction}).

\section{Initiality}
\label{sec:oitinitiality}

Another way of stating that $T$ has a type formation and introduction
rule is saying that $T$ admits an algebra structure:
$(T : \Type , c : FT \to T) : \algcat{F}$. The category $\algcat{F}$
has objects:
$$
| \algcat{F} | \ddefeq (X : \Type) \times (\theta : FX \to X)
$$
and for algebras $(X,\theta)$ and $(Y,\rho)$, we have morphisms:
$$
\algcat{F}((X,\theta),(Y,\rho)) \ddefeq (f : X \to Y) \times (f_0 : (x : FX) \to f\ (\theta\ x) = \rho\ (F\ f\ x)
$$
We can think of algebra morphisms $\algcat{F}((X,\theta),(Y,\rho))$ as
functions $f : X \to Y$ that come with a computation rule $f_0$. If an
algebra $(T,c)$ is initial, there exists a function $\rec : X \to Y$
to any $Y : \Type$ that has an algebra $\rho : FY \to Y$. The
existence of this function along with its computation rule is also
called the \emph{recursion principle} of $T$ with $\rec$ the
\emph{recursor} or \emph{non-dependent eliminator}. Apart from
requiring that there exists an algebra morphism to any algebra, this
morphism must also be unique. In fact, this uniqueness allows us to
show that initiality coincides with the induction principle
(\cref{sec:oitsectioninitiality}).

A concise way of stating that an algebra $\alg{X}$ is initial is
requiring that for any algebra $\alg{Y}$ the type of morphisms
$\algcat{F}(\alg{X},\alg{Y})$ is contractible:
%
\begin{align*}
&\isinitial : \algcat{F} \to \Type \\
&\isinitial \alg{X} \ddefeq (\alg{Y} : \algcat{F}) \to \iscontr (\algcat{F}(\alg{X},\alg{Y}))
\end{align*}
%
Expressing initiality this way makes it apparent that
$\isinitial \alg{X}$ is a proposition since $\iscontr$ is
propositional and $\Pi$-types into propositions are propositional
themselves.

\section{Induction principle}
\label{sec:oitinduction}

The induction principle of an inductive type $T$ gives us a method to
show that for a family $P : T \to \Type$, for all $x : T$, $P\ x$ is
inhabited. Intuitively we have to show for each constructor $c$ that
if $P$ holds for all $T$-subterms of $x$, then $P$ holds for $c\
x$.
For example, for the natural numbers, we have the induction operator:
%
\begin{alignat*}{2}
  \indnat &:   &&\ (P : \Nat \to \Type) \\
          &    &&\ (m_{\zero} : P\ \zero) \\
          &    &&\ (m_{\suc} : (n : \Nat) \to P\ n \to P\ (\suc\ n)) \\
          &\to &&\ (x : \Nat) \to P\ x
\end{alignat*}
%
$P$ is usually referred to as the \emph{motive} of the induction, with
the functions $m_{\zero}$ and $m_{\suc}$ the \emph{methods}. The
induction operator also comes with computation rules that tell us how
the introduction and elimination rules interact:
%
\begin{align*}
  &\indnatzero_0\ P\ m_{\zero}\ m_{\suc} : \\
  &\ \ \indnat\ P\ m_{\zero}\ m_{\suc}\ \zero\ =\ m_{\zero} \\
  \\
  &\indnatsucc_0\ P\ m_{\zero}\ m_{\suc}  : \\
  &\ \ \indnat\ P\ m_{\zero}\ m_{\suc}\ (\suc\ k)\ =\ m_{\suc}\ k\ (\indnat\ P\ m_{\zero}\ m_{\suc}\ k)
\end{align*}
%
Another way of stating the induction principle for $\Nat$ is that for
any \emph{$\Nat$-algebra family} (the family $P$ along with its
methods) we get a \emph{dependent $\Nat$-algebra morphism} ($\indnat$
along with its computation rules). Note that usually the computation
laws for $\indnat$ hold strictly. Since we are working inside type
theory, we cannot state that a computation rule holds strictly, hence
all the rules hold up to propositional equality.

Defining what constitutes an algebra family for a functor
$F : \Type \to \Type$ requires us to be able to state that a family
$P : T \to \Type$ is inhabited for all $T$-subterms of $x : FT$. We
will do this by introducing a modality
$\Box_F : (A \to \Type) \to FA \to \Type$. This modality is the action
of $F$ on families in $\Type$ and is defined by the following
equation, for $A : \Type$, $B : A \to \Type$:
$$
F (\Sigma\ A\ B) = \Sigma\ FA\ (\Box_{F} B)
$$
By singleton elimination we can then give the following definition of $\Box_{F}\ B$:
$$
\Box_{F}\ B\ x = (y : F (\Sigma\ A\ B)) \times (F\ \pi_1\ x = y)
$$
As we sometimes need to refer to it explicitly, we will give the
witness of the isomorphism a name:
$$
\phi : F (\Sigma\ A\ B) \to \Sigma\ FA\ (\Box_{F} B)
$$
Using this modality we can define what an algebra family is:
%
\begin{defn}
  An \emph{$F$-algebra family} over an algebra $(X,\theta)$, denoted
  $\Famover{\algcat{F}}{(X,\theta)}$, consists of:

  \begin{itemize}
  \item a motive $P : X \to \Type$
  \item a method $m : (x : F\ X) \to \Box_F\ P\ x \to P\ (\theta\ x)$
  \end{itemize}
\end{defn}
%
To define dependent algebra morphisms, we need to define the action of
$F$ on dependent functions:
%
\begin{align*}
&\actionsection{F} : (f : (x : A) \to B\ x) \to (x : FA) \to \Box_F\ B\ x \\
&\actionsection{F} f x \ddefeq (F\ (\lambda z . (z , f\ z))\ x, \refl)
\end{align*}
%
\begin{defn}
  A \emph{dependent $F$-algebra morphism} of an an $F$-algebra family
  $(P,m) : \Famover{\algcat{F}}{(X,\theta)}$ over algebra
  $(X,\theta)$, which is denoted as $\DepHom{\algcat{F}}{(P,m)}$,
  consists of:

  \begin{itemize}
  \item a dependent function $f : (x : X) \to P\ x$, along with
  \item a computation rule $f_0 : (x : FX) \to f\ (\theta\ x) = m\ x\ (\actionsection{F}\ f\ x)$
  \end{itemize}
\end{defn}

Now we have all the ingredients to specify the induction principle:

\begin{defn}
  An algebra $(T,c) : \algcat{F}$ satisfies the \emph{induction
    principle} if for every algebra family
  $(P,m) : \Famover{\algcat{F}}{(T,c)}$ there is a dependent algebra
  morphism $(\ind,\ind_0) : \DepHom{\algcat{F}}{(P,m)}$.
\end{defn}

So far we have been careful to avoid the words ``fibration'' and
``section''. In $\Type$, giving a family over a type $A : \Type$ is
the same as giving a function into $A$, or a \emph{fibration}, \ie:
$$
(A \to \Type) = (B : \Type) \times (p : B \to A)
$$
A dependent function then corresponds to a \emph{section} of the
fibration $p$. As such, the terms ``dependent function'' and
``section'' are sometimes used
interchangeably. In~\cref{sec:oitsectioninduction} we will show that
giving a family over an algebra $\alg{X} : \algcat{F}$ is the same as
giving an algebra morphism into $\alg{X}$:
$$
\Famover{\algcat{F}}{\alg{X}} = (\alg{Y} : \algcat{F}) \times \algcat{F}(\alg{Y},\alg{X})
$$

\section{Section principle}
\label{sec:oitsection}

Instead of showing directly that the induction principle is logically
equivalent to homotopy initiality, we introduce another principle that
is somewhere in between the type theoretic induction principle and the
categorical notion of initiality. In~\cref{sec:oitinduction}, the
induction principle for an inductive type $T$ with constructor
$c : FT \to T$ gives us for every algebra family
$(P,m) : \Famover{\algcat{F}}{(T,c)}$, a dependent algebra morphism
$(\ind,\ind_0) : \DepHom{\algcat{F}}(P,m)$. The section principle
states that every \emph{algebra fibration} has a \emph{section}:
%
\begin{defn}
  An \emph{$F$-algebra fibration} over an algebra $\alg{X}$ is an
  algebra $\alg{Y}$ along with an algebra morphism
  $\algcat{F}(\alg{Y},\alg{X})$. The type of $F$-algebra fibrations
  over $\alg{X}$ is denoted as $\fibover{\algcat{F}}{\alg{X}}$
\end{defn}
%
\begin{defn}
  Given an algebra fibration
  $(\alg{Y},p) : \fibover{\algcat{F}}{\alg{X}}$, a \emph{section} of
  $(\alg{Y},p)$ (denoted $\sectionof{\algcat{F}}{(\alg{Y},p)}$) is a
  morphism $s : \algcat{F}(\alg{X},\alg{Y})$ along with
  $s_0 : p \circ s = \Id{\alg{X}}$.
\end{defn}
%
\begin{defn}
  An algebra $\alg{X}$ satisfies the \emph{section principle} if for
  every algebra fibration
  $\algfib{P} : \fibover{\algcat{F}}{\alg{X}}$, there exists a section
  $\algsect{s} : \sectionof{\algcat{F}}{\algfib{P}}$.
\end{defn}
%
Note that in order for this to be a complete definition, we have to
define composition of algebra morphisms and define the identity
morphisms. This will be done in~\cref{sec:oitalgcat}.

\section{Induction principle is logically equivalent to section principle}
\label{sec:oitsectioninduction}

To show that the induction and the section principle are logically
equivalent, we need to show that, given an algebra
$\alg{X} : \algcat{F}$:
$$
(\algfam{P} : \Famover{\algcat{F}}{\alg{X}}) \to \DepHom{\algcat{F}}{\algfam{P}}
$$
is logically equivalent to:
$$
(\algfib{P} : \fibover{\algcat{F}}{\alg{X}}) \to \sectionof{\algcat{F}}{\algfib{P}}
$$
We first have to show that $\Famover{\algcat{F}}{\alg{X}}$ is equivalent
to $\fibover{\algcat{F}}{\alg{X}}$. 


For a type family $A
: \Type, B : A \to \Type$, we have the $\Sigma$-type $\Sigma A B :
\Type$ along with a projection into $A$: $\pi_1 : \Sigma A B \to
A$. For
$F$-algebra
families we have similar operations, that we will call $\total$
for \emph{total space} and $\proj$,
the project out of the total space into its base space:
\begin{align*}
  &\total : \Famover{\algcat{F}}{(X,\theta)} \to \algcat{F} \\
  &\total\ (P, m) \ddefeq (\Sigma X P, \lambda x . (\theta\ (F\ \pi_1\ x) , \uncurry m \circ \phi)) \\
  &\\
  &\proj : (\algfam{P} : \Famover{\algcat{F}}{(X,\theta)}) \to \algcat{F}(\total \algfam{P}, (X,\theta)) \\
  &\proj\ (P, m) \ddefeq (\pi_1 , \lambda x . \refl)
\end{align*}


\section{Section principle is logically equivalent to initiality}
\label{sec:oitsectioninitiality}

We will first show that initiality implies the section principle.

\begin{prop}
  If $\alg{X} : \algcat{F}$ is initial, then every morphism
  $\algcat{F}(\alg{Y},\alg{X})$ admits a section.
\end{prop}

\begin{proof}
  Suppose $\alg{X} : \algcat{F}$ is initial, $\alg{Y} : \algcat{F}$
  and $p : \algcat{F}(\alg{Y},\alg{X})$. Since $\alg{X}$ is initial,
  there is a morphism $s : \algcat{F}(\alg{X},\alg{Y})$. Since
  $\alg{X}$ is initial, there is only one morphism
  $\algcat{F}(\alg{X},\alg{X})$, namely $\Id{\alg{X}}$, hence
  $p \circ s = \Id{\alg{X}}$, therefore $s$ is a section of $p$ and we
  are done.
\end{proof}

To prove the converse, we need to appeal to more of the category
structure of $\algcat{F}$:

\begin{prop}
  If $\alg{X} : \algcat{F}$ satisfies the section principle, then it
  is initial.
\end{prop}

\begin{proof}
  Let $\alg{X} : \algcat{F}$ be an algebra that satisfies the section
  principle, then we have to show that for any algebra
  $Y : \algcat{F}$ there exists a unique algebra morphism
  $f : \algcat{F}(\alg{X},\alg{Y})$. Given $\alg{X}$ and $\alg{Y}$, we
  can form the product of algebras $\alg{X} \times \alg{Y}$, which
  comes with projections
  $\pi_1 : \algcat{F}(\alg{X} \times \alg{Y}, \alg{X})$ and
  $\pi_2 : \algcat{F}(\alg{X} \times \alg{Y}, \alg{Y})$. Let
  $s : \algcat{F}(\alg{X},\alg{X} \times \alg{Y})$ be the section of
  $\pi_1$. We can then construct the $f$ as follows:
$$
\xymatrix{ &\alg{X} \ar[r]^-{s} &\alg{X} \times \alg{Y}
  \ar[r]^-{\pi_2} &\alg{Y} }
$$
Now we have to show that for any $g : \algcat{F}(\alg{X},\alg{Y})$,
$f = g$. This can be done by constructing the equaliser $\alg{E}$ of
$f$ and $g$:
$$
\xymatrix{ &\alg{E} \ar[r]^{e} &\alg{X} \ar@<-.5ex>[r]_-{g}
  \ar@<.5ex>[r]^-{f} &\alg{Y} }
$$
We get a section $s : \algcat{F}(\alg{X},\alg{E})$ of $e$, which then
shows that $f = g$:
$$
\xymatrix{
  &\alg{E} \ar[r]^{e} &\alg{X} \ar@<-.5ex>[r]_-{g} \ar@<.5ex>[r]^-{f} &\alg{Y} \\
  &\alg{X} \ar[u]^{s} \ar[ur]_{\Id{\alg{X}}} }
$$
\end{proof}

\section{Category of algebras}
\label{sec:oitalgcat}

When showing that the section principle implies initiality, we had to
use quite a bit of the category structure of $\algcat{F}$. First of
all for the definition of the section principle we need to have
composition and identity morphisms. Apart from that, we need to be
able to construct equalisers and have proofs of the identity laws and
associativity. As it turns out $\algcat{F}$ (unlike $\Type$) is not a
\emph{strict category}: it does not satisfy the category laws strictly
but only weakly.

In this section we will assume that $F$ is given as a container, which
means that it satisfies the functor laws strictly, simplifying the
equational, reasoning.

\subsection{Identity morphisms}

Given an algebra $(X,\theta)$ we can construct the identity morphism as follows:
%
\begin{align*}
  &\Id{(X,\theta)} : \algcat{F}((X,\theta),(X,\theta)) \\
  &\Id{(X,\theta)} \ddefeq (\id{X} , \ido{(X,\theta)})
\end{align*}
%
where
%
\begin{align*}
  &\ido{(X,\theta)} : (x : FX) \to \id{X}\ (\theta\ x) = \theta\ (F\ \id{X}\ x) \\
  &\ido{(X,\theta)}\ x\ \ddefeq \\
  &\ \ \ \id{X}\ (\theta\ x) \\
  &\ \ \ \defeq \reasontext{$\Type$ is a strict category} \\
  &\ \ \ \theta\ x \\
  &\ \ \ \defeq \reasontext{$F$ is a strict functor} \\
  &\ \ \ \theta\ (F\ \id{X}\ x)
\end{align*}
%
\ie, $\ido{(X,\theta)} x \defeq \refl$.

\subsection{Composition}

Given three algebras $(X,\theta), (Y,\rho), (Z,\zeta)$ and morphisms
$(g,g_0) : (Y,\rho) \to (Z,\zeta)$,
$(f,f_0) : (X,\theta) \to (Y,\rho)$, we need to construct a morphism
$(X,\theta) \to (Z,\zeta)$:
%
\begin{align*}
  &(g,g_0) \circ (f,f_0) : \algcat{F}((X,\theta),(Y,\rho)) \\
  &(g,g_0) \circ (f,f_0) \ddefeq (g \circ f , g_0 \circ_0 f_0)
\end{align*}
%
where
%
\begin{align*}
  &g_0\ \circ_0 f_0 : (x : FX) \to (g \circ f)\ (\theta\ x)) = \zeta\ (F\ (g \circ f)\ x) \\
  &(g_0\ \circ_0\ f_0)\ x \ddefeq \\
  &(g \circ f)\ (\theta\ x) \\
  &\defeq \reasontext{definition of $\circ$} \\
  &g\ (f\ (\theta\ x)) \\
  &= \reasonterm{\ap\ g\ (f_0\ x)} \\
  &g\ (\rho\ (F\ f\ x)) \\
  &= \reasonterm{g_0\ (F\ f\ x)} \\
  &\zeta\ (F\ g\ (F\ f\ x)) \\
  &\defeq \reasontext{$F$ is a strict functor} \\
  &\zeta\ (F\ (g \circ f)\ x)
\end{align*}
%
Note that if $F$ is given as a container, it satisfies the functor
laws strictly, which simplifies the definition of algebra morphism
composition.

\subsection{Equality of algebra morphisms}

In order to prove the category laws, we need to know what the equality
of algebra morphisms looks like. Let $(X,\theta)$ and $(Y, \rho)$ be
algebras and $(f,f_0) ,(g, g_0) : \algcat{F}((X,\theta),(Y,\rho))$,
then, since we know that an equality of two dependent pairs is a
dependent pair of equalities and using function extensionality, we
get that the type $(f,f_0) = (g,g_0)$ is equivalent to:
$$
(p : f = g) \times (p_0 : (x : FX) \to f_0 = g_0 [ \lambda h . h (\theta\ x) = \rho (F h x) \downarrow p ])
$$
As we will see for the category laws, since $\Type$ is a strict
category hence the $p$ part of algebra morphism equalities will be
$\refl$ and $p_0$ will, reduce to an non-dependent path. If $p$ is
non-trivial, we can still simplify the $p_0$ part. Giving $p_0$
amounts to giving the following square for every $x : FX$:
$$
\xymatrix{
f (\theta\ x) \ar@{-}[d]_{f_0 x} \ar@{-}[r]^{\ap\ (\lambda h . h (\theta\ x)) p}  &g (\theta\ x) \ar@{-}[d]^{g_0 x} \\
\rho (F f x) \ar@{-}[r]_{\ap\ (\lambda h . \rho (F h x)) p} &\rho (F g x) }
$$

\subsection{Identity laws}

Let $(f , f_0) : \algcat{F}((X,\theta),(Y,\rho))$ be an algebra
morphism. We need to show that
$\Id{(Y,\rho)} \circ (f , f_0) = (f , f_0) \circ \Id{(X,\theta)} =
(f,f_0)$.

Since $\Type$ satisfies the category laws strictly, we only need to
focus on $f_0 \circ_0 \ido{(X,\theta)}$, $\ido{(X,\theta)} \circ_0 f_0$
and $f_0$. For $x : FX$, we have:
%
\begin{align*}
  &(f_0 \circ_0 \ido{(X,\theta)})\ x \\
  &\defeq \reasontext{definition of $\circ_0$}\\
  &\ap\ f\ (\ido{(X,\theta)}\ x) \ct f_0\ (F\ \id{X}\ x) \\
  &\defeq \reasontext{$F$ is a strict functor} \\
  &\ap\ f\ (\ido{(X,\theta)}\ x) \ct f_0\ x \\
  &\defeq \reasontext{$\ido{(X,\theta)}\ x$ is $\refl$} \\
  &\refl \ct f_0\ x \\
  &= \\
  &f_0\ x
\end{align*}
%
The proof of $(\ido{(Y,\rho)} \circ_0 f_0)\ x = f_0\ x$ goes in a similar
fashion. Whether the entire proof reduces to reflexivity depends on
how path composition is defined: if it is defined by induction on the
left argument, the left identity law holds strictly but the right
identity law does not, and vice versa. If path composition is defined
by induction on both arguments, then neither law holds strictly.

\subsection{Associativity}

Given three algebra morphisms:
$$
(X,\theta) \overset{(f,f_0)}\longrightarrow 
(Y,\rho) \overset{(g,g_0)}\longrightarrow
(Z,\zeta) \overset{(h,h_0)}\longrightarrow
(W,\omega)
$$
we need to show that:
$$
((h,h_0) \circ (g,g_0)) \circ (f,f_0) = (h,h_0) \circ ((g,g_0) \circ (f,f_0)) = 
$$
As with the identity laws, associativity holds strictly for the
underlying functions, so we need to show for every $x : FX$ that:
$$
((h_0 \circ_0 g_0) \circ_0 f_0)\ x = (h_0 \circ (g_0 \circ_0 f_0))\ x
$$
This can by shown by appealing to functoriality of $\ap$ (in both its
arguments) and using naturality of homotopies.

\subsection{Products}

Given algebras $(X,\theta)$ and $(Y,\rho)$, we can define their
product $(X,\theta) \times (Y,\rho)$ as follows:
%
\begin{align*}
  &(X,\theta) \times (Y,\rho) : \algcat{F}\\
  &(X,\theta) \times (Y,\rho) \ddefeq (X \times Y , \lambda x . (\theta\ (F\ \pi_1\ x) , \rho\ (F\ \pi_2\ x)))
\end{align*}
%
The projections $\pi_1$ and $\pi_2$ are then also strict algebra morphisms.

\subsection{Equalisers}

Given algebras $(X,\theta), (Y,\rho)$ and a parallel pair of morphisms
$(f,f_0),(g,g_0) : \algcat{F}((X,\theta),(Y,\rho))$, we need to find
an algebra $(E,\epsilon)$ along with morphism
$(e,e_0) : \algcat{F}((E,\epsilon),(X,\theta))$ such that the
following commutes:
$$
\xymatrix{ &(E,\epsilon) \ar[r]^{(e,e_0)} &(X,\theta) \ar@<-.5ex>[r]_-{(g,g_0)}
  \ar@<.5ex>[r]^-{(f,f_0)} &(Y,\rho) }
$$
We can $E$ to be the equaliser (in $\Type$) of $f$ and $g$, \ie:
$$
E \ddefeq (x : X) \times (f x = g x)
$$
and define $e : E \to X$ as the first projection: $e \ddefeq \pi_1$.
We define $p : e \circ f = e \circ g$ by function extensionality:
$p \ddefeq \funext \pi_2$. We have to define an algebra
structure $\epsilon : FE \to E$ such that $e : E \to X$ becomes an
algebra morphism, \ie for all $x : FE$,
$\pi_1 (\epsilon x) = \theta (F \pi_1 x)$, so we only have to define
$\pi_2 (\epsilon x) : f (\theta (F\ e\ x)) = g (\theta (F\ e\ x))$. We
define $\pi_2 (\epsilon x)$ as the path:
%
\begin{align*}
  &f\ (\theta\ (F\ e\ x)) \\
  &= \reasonterm{f_0\ (F\ e\ x)} \\
  &\rho\ (F\ f\ (F\ e\ x)) \\
  &\defeq \reasontext{$F$ is a strict functor} \\
  &\rho\ (F\ (f \circ e)\ x) \\
  &= \reasonterm{\ap\ (\lambda h . \rho\ (F\ h\ x))\ p} \\
  &\rho\ (F\ (g \circ e)\ x) \\
  &\defeq \reasontext{$F$ is a strict functor} \\
  &\rho\ (F\ g (F\ e\ x)) \\
  &= \reasonterm{g_0\ (F\ e\ x)^{-1}} \\
  &g\ (\theta\ (F\ e\ x))
\end{align*}
%
Note that by construction, $e_0\ x \defeq \refl$. We still have to show
that composing $(e,e_0)$ with $(f,f_0)$ or $(g,g_0)$ yields the same
results, so we have to give:
$$
p : f \circ e = g \circ e
$$
and for all $x : FE$ the square:
$$
\xymatrix{
f\ (e\ (\epsilon\ x)) 
  \ar@{-}[r]^{\ap\ (\lambda h . h\ (\epsilon x))\ p} 
  \ar@{-}[d]_{f_0\ (F\ e\ x)}  
&g (e\ (\epsilon\ x)) 
  \ar@{-}[d]^{g_0\ (F\ e\ x)}
\\
\rho\ (F\ (f \circ e)\ x)
  \ar@{-}[r]_{\ap\ (\lambda h . \rho\ (F\ h\ x))\ p}
&\rho\ (F\ (g \circ e)\ x)}
$$

We do not need to show that our equaliser satisfies the universal
property as this is not used by the proof that the section principle
implies initiality.

\section{Free monads}
\label{sec:oitfreemonad}

Given a functor $F : \Type \to \Type$, we can consider the functor
$F^*$, defined pointwise as the inductive type:
%
\begin{alignat*}{2}
  &\rlap{$\data\ F^*\ (X : \Type)\ :\ \Type\ \where$} \\
  &&\ \ \eta &:\ X \to F^* X \\
  &&\ \ c    &:\ F(F^*X) \to F^* X
\end{alignat*}
%
The join operator $\mu : F^*F^* X \to X$ can be defined by
recursion. Note that if $F$ is strictly positive, the functor
$\lambda X . X + FX$ is also strictly positive, hence the above
inductive type exists for $F$ strictly positive. Furthermore, if $F$
is given as a container, we can also find a container representation
of $F^*$.

Free monads are interesting for two reasons. The first reasons is that
they give us an adjunction $L \dashv U$ between $\Type$ and
$\algcat{F}$, where:
%
\begin{align*}
  &U : \algcat{F} \to \Type \\
  &U (X, \theta) \ddefeq X \\
  &\\
  &L : \Type \to \algcat{F} \\
  &L X \ddefeq (F^* X, c)
\end{align*}
%
The other reason they are interesting is that functor algebras
$\algcat{F}$ are equivalent to monad algebras $\Algcat{F^*}$. This
allows us to think of \oits as being given by free monads. \Hits are
then a generalisation of free monads to \emph{presented monads}, \ie
apart from being generated by only generators, we also have
(proof-relevant) relations on them.

\chapter{Initiality and induction for \hits}
\label{sec:hits}

In this section we will attempt to generalise the previous
constructions to \hits. Naturally, the categorical concepts generalise
without change: initiality, algebra fibrations and their sections and
the proof that initiality and the section principle are logically
equivalent can be used directly, given that the categorical structure
needed for them is present. Starting out with the most general
approach, we will see that we can define the objects and morphisms of
the categories of algebras without any issues. Adding any more
categorical structure, however, turns out to be problematic, as we run
into coherence issues.

We have seen that a \hit can be described as a sequence of pairs of
functors, where the domain of the functors depends on the category of
algebras of all the previous constructors. Since we are only concerned
with establishing an induction principle, defining the category of
algebras and showing that the induction principle and initiality
coincide, we do not immediately need to restrict ourselves to strictly
positive functors. We will also not put restrictions on the target
functors a priori to see how far we can get without them.

\section{Specification}
\label{sec:hitspec}

In order to specify a (higher) constructor, we need to give an
arguments functor and target functor out of an appropriate category:
%
\begin{align*}
  &\Constr\ \C \ddefeq (F : \C \To \Type) \times (G : \int_\C\ F \To \Type)
\end{align*}
%
where we expect $\C$ to be either $\Type$ or some category of algebras
consisting of all the previous constructors. Given the specification
of a constructor, we can extend the category $\C$ to a category of
algebras with this new constructor:
%
\begin{align*}
  &\extend : (\C : \Cat) \to \Constr\ \C \to \Cat
\end{align*}
%
At the moment we have not defined what $\Cat$ is and consequently what
the type of functors $\To$ is. We will start with the minimum, \ie
objects, and try to add more and more structure as needed and see
where we run into coherence issues and how we can possibly avoid
those.

The objects of $\C$ extended with a constructor $(F,G) : \Constr\ \C$ are:
$$
(X : \C) \times (\theta : (x : FX) \to G\ (X,x))
$$
A morphism $(X, \theta) \to (Y, \rho)$ consists of:
$$
(f : \C(X,Y)) \times (f_0 : (x : FX) \to G\ (\lift f\ x)\ (\theta\ x) = \rho\ (F\ f\ x))
$$
where:
%
\begin{align*}
&\lift : (f : \C(X,Y))\ (x : FX) \to \int_{C}\ F ((X,x),(Y,F\ f\ x)) \\
&\lift f\ x \ddefeq (f , \refl)
\end{align*}
%

We can now formalise such a specification of a \hit as the following
inductive-recursive definition:
%
\begin{align*}
  &\Spec : \Type \\
  &\Alg : \Spec \to \Cat \\
  \\
  &\data\ \Spec\ \where \\
  &\ \ \epsilon : \Spec \\
  &\ \ \_,\_ : (s : \Spec) \to \Constr\ (\Alg\ s) \to \Spec \\
  \\
  &\Alg\ \epsilon \ddefeq \Type\\
  &\Alg\ (s , c) \ddefeq \extend\ (\Alg\ s)\ c
\end{align*}
%
Since we have defined objects and morphisms, we have enough
categorical structure to use our previous definitions of initiality
and algebra fibrations. 

\section{Algebra families}
\label{sec:algfamhits}
In order to define algebra families , we need to generalise the $\Box$
modality from acting on families in $\Type$ to acting on families in
$\C$. We can define for $F : \Alg_s \To \Type$ and
$G : \int_{\Alg_s}\ F \To \Type$ the following mutually by induction
on $s : \Spec$, assuming $\alg{X} : \Alg_s$ and
$\algfam{P} : \Fam_s \alg{X}$:
%
\begin{alignat*}{4}
  &\Fam_s\ &&\alg{X}             &&: \Alg_s \to \Type&\\
  &\Box_F\ &&\alg{X}\ \algfam{P} &&: F \alg{X} \to \Type&\\
  &\Box_G\ &&\alg{X}\ \algfam{P} &&: (x : F \alg{X}) (y : \Box_F\ \alg{X} \ \algfam{P}\ x) \to G (\alg{X} , x) \to \Type&\\
  &\total\ &&\alg{X}\ \algfam{P} &&: \Alg_s&\\
  &\proj\  &&\alg{X}\ \algfam{P} &&: \Alg_s(\total\ \alg{X}\ \algfam{P}, \alg{X})&\\
  &\phi_F\ &&\alg{X}\ \algfam{P} &&: \Sigma (F \alg{X}) (\Box_F\ \alg{X}\ \algfam{P}) \to F (\total\ \alg{X}\ \algfam{P})&\\
  &\phi_G\ &&\alg{X}\ \algfam{P} &&: (x : F \alg{X}) (y : \Box_F\ \alg{X} \ \algfam{P}\ x) &\\
  &&&&&\to \Sigma (G\ (\alg{X},x)) (\Box_G\ \alg{X}\ \algfam{P}\ x\ y) 
            \to G (\total\ \alg{X}\ \algfam{P}, \phi_F\ \alg{X}\ \algfam{P} (x , y)) &
\end{alignat*}
%
where $\Fam_s$ is defined as:
\begin{align*}
  &\Fam_\epsilon X &&\ddefeq X \to \Type \\
  &\Fam_{s,(F,G)} (\alg{X},\theta) &&\ddefeq (\algfam{P} : \Fam_s\ \alg{X}) \\ 
  &&&\times\ (m : (x : FX) \times (y : \Box_F\ \alg{X}\ \algfam{P}\ x) \to \Box_G\ \alg{X}\ \algfam{P}\ x\ y\ (\theta\ x)
\end{align*}
%
The other functions are defined in the same manner as for $\algcat{F}$
as we have seen in~\cref{sec:oits}.

\section{Category structure and coherence issues}
\label{sec:hitscategory}

While we the above specification of \hits allows us to define algebras
and algebra morphisms, we run into coherence issues as soon as we try
to add more category structure. To add more category structure, we
need to change the definition of $\Cat$ and hence the definitions of
$\extend$. Since the definition of $\extend$ depends on functors, we
also need the given functors to preserve the added structure. There is
also the added complexity of the target functors $G$ being
``dependent'' functors, \ie functors out of $\int_\C F$. In this
section we will first show how this dependency causes issues when
trying to add category structure. We will then show that even if we
did not have this dependency, \ie we considered ordinary dialgebras
$\theta : F X \to G X$ with $F, G : \C \to \Type$, then we run into
coherence issues elsewhere.

If we want to add identity morphisms to $\Cat$, we we want to extend
the function $\extend$ to also have an operation
$\Id{} : (\alg{X} : \Alg_s) \to \Alg_s(\alg{X},\alg{X})$, for any
specification $s : \Spec$. We can try to define identity morphisms by
doing induction on a specification $s : \Spec$. For the base case
where $s \defeq \epsilon$, $\Alg_s \defeq \Type$ hence we can define
the identity for object $X : \Type$ as $(\lambda x . x) : X \to X$. For
the inductive case, we get the following:
%
\begin{itemize}
\item $s : \Spec$ 
\item $c : \Constr\ Alg_s$, \ie $F : \Alg_s \to \Type$ and $G : \int_{\Alg_s} F \to \Type$
\item $\alg{X} : \Alg_s$ along with
  $\Id{\alg{X}} : \Alg_s (\alg{X},\alg{X})$
\item  $\theta : (x : F \alg{X}) \to G (\alg{X}, x)$
\end{itemize}
%
Given this, we need to specify a morphism
$f : \Alg_s (\alg{X},\alg{X})$ with
$f_0 : (x : F \alg{X}) \to G (\lift f\ x) (\theta\ x) = \theta (F\ f\
x))$.
By induction, we are given a morphism $\Alg_s (\alg{X},\alg{X})$ which
is our only candidate for $f$. To define $f_0$, we have to give a path, for $x : F \alg{X}$:
$$
G (\lift \Id{\alg{X}}\ x) (\theta\ x) = \theta (F\ \Id{\alg{X}}\ x))
$$
If we require functors to preserve identities, we would have the equation:
$$
F\ \Id{\alg{X}}\ x = x
$$
For $G$ it is different, as
$\lift \Id{\alg{X}} x : \int_{\Alg_s} F ((\alg{X},x), (\alg{X}, F\
\Id{\alg{X}}\ x)$,
whereas the identity morphism of $\int_{\Alg_s} F$ would have type
$\int_{\Alg_s} F ((\alg{X},x),(\alg{X},x))$, which are not
definitionally the same, unless $F$ happens to satisfy the functor
laws strictly, which is not something we can assume in \mltt.

\section{Non-dependent dialgebras}
\label{sec:nondepdialg}

In order to avoid the problem mentioned above, we can restrict
ourselves to \emph{non-dependent} dialgebras, \ie we consider target
functors $G : \C \to \Type$ instead. This restriction rules out
certain \hits such as propositional truncation, but it still includes
interesting examples such as the torus. It is also a good way to see
what 

\subsection{Identity morphisms}

In this setting we can define
identity morphisms and composition, which again happens by induction
over the specification $s : \Spec$. The base case is the same as
before and the interesting part is the inductive case, where we get
the following data:
%
\begin{itemize}
\item $s : \Spec$ 
\item $c : \Constr\ Alg_s$, \ie $F : \Alg_s \to \Type$ and $G : \Alg_s \to \Type$
\item $\alg{X} : \Alg_s$ along with
  $\Id{\alg{X}} : \Alg_s (\alg{X},\alg{X})$
\item  $\theta : F \alg{X} \to G \alg{X}$
\end{itemize}
%
Given this, we need to specify a morphism
$f : \Alg_s (\alg{X},\alg{X})$ with
$f_0 : (x : F \alg{X}) \to G\ f\ (\theta\ x) = \theta (F\ f\ x))$.
Again for, for $f$ we choose $\Id{\alg{X}}$. Now suppose $F$ and $G$
preserve identity morphisms, \ie we have a term
$\Fid_{\alg{X}} : (x : F \alg{X}) \to F\ \Id{\alg{X}}\ x = x$, and
similarly a term $\Gid_{\alg{X}}$, then we can define $f_0$ as
follows, given $x : F \alg{X}$:
%
\begin{align*}
  &G\ \Id{\alg{X}}\ (\theta\ x) \\
  &= \reasonterm{\Gid_{\alg{X}} (\theta\ x)} \\
  &\theta\ x \\
  &= \reasonterm{\ap\ \theta\ (\Fid_{\alg{X}}\ x)^{-1}} \\
  &\theta\ (F\ \Id{\alg{X}}\ x)
\end{align*}
%

\subsection{Composition}
We can also define composition by induction on $s : \Spec$. The base
case is again trivial as we just use ordinary composition of functions
for $\Type$. For the inductive case we get the following:
%
\begin{itemize}
\item $s : \Spec$ 
\item $c : \Constr\ Alg_s$, \ie $F : \Alg_s \to \Type$ and $G : \Alg_s \to \Type$
\item $\alg{X}, \alg{Y}, \alg{Z} : \Alg_s$ along with algebras:
\item $\theta : F \alg{X} \to G \alg{X}$, $\rho : F \alg{Y} \to G \alg{Y}$, $\zeta : F \alg{Z} \to G \alg{Z}$
\item $f : \Alg_s(\alg{X},\alg{Y})$, $f_0 : (x : F \alg{X}) \to G\ f\ (\theta\ x) = \rho\ (F\ f\ x)$
\item $g : \Alg_s(\alg{Y},\alg{Z})$, $g_0 : (x : F \alg{X}) \to G\ g\ (\rho\ x) = \zeta\ (F\ g\ x)$
\item $g \circ f : \Alg_s(\alg{X},\alg{Z})$
\end{itemize}
%
We have to define:
%
\begin{itemize}
  \item $h : \Alg_s(\alg{X},\alg{Z})$
  \item $h_0 : (x : F \alg{X}) \to G\ h\ (\theta\ x) = \zeta\ (F\ h\ x)$
\end{itemize}
%
For $h$ we can choose it to be $g \circ f$, so we need to give a term
of type
$(x : F \alg{X}) \to G\ (g \circ f)\ (\theta\ x) = \zeta\ (F\ (g \circ
f)\ x)$.
Just like we needed the functors $F$ and $G$ to preserve identity
morphisms in order to define them in the inductive case, we need $F$
and $G$ to also preserve composition, \ie we have terms
$\Fcomp\ g\ f : (x : F \alg{X}) \to F\ (g \circ f) x = F\ g\ (F\ f\ x)$ and
the same for $G$. Given these, we can define $h_0$ as follows, given
$x : F \alg{X}$:
%
\begin{align*}
  &G\ (g \circ f)\ (\theta\ x) \\
  &= \reasonterm{\Gcomp\ g\ f\ (\theta\ x)} \\
  &G\ g\ (G\ f\ (\theta\ x)) \\
  &= \reasonterm{\ap\ (G\ g)\ (f_0\ x)} \\
  &G\ g\ (\rho\ (F\ f\ x)) \\
  &= \reasonterm{g_0\ (F\ f\ x)} \\
  &\zeta\ (F\ g\ (F\ f\ x)) \\
  &= \reasonterm{\ap\ \zeta\ (\Fcomp\ g\ f\ x)^{-1}} \\
  &\zeta\ (F\ (g \circ f)\ x)
\end{align*}

\subsection{Equality of algebra morphisms}

In order to show the identity laws and associativity, we need to be
able to talk about equality of algebra morphisms. The data needed to
show that two morphisms are equal can be defined by induction on
$s : \Spec$: for functions $f, g$ in $\Type$ it is just $f = g$. In
the inductive case, we have:
%
\begin{itemize}
\item $\alg{X}, \alg{Y} : \Alg_s$
\item $\theta : F \alg{X} \to G \alg{X}$ and $\rho : F \alg{Y} \to G \alg{Y}$
\item $f, g : \Alg_s(\alg{X},\alg{Y})$
\item $f_0 : (x : F \alg{X}) \to G\ f\ (\theta\ x) = \rho\ (F\ f\ x)$
\item $g_0 : (x : F \alg{X}) \to G\ g\ (\theta\ x) = \rho\ (F\ g\ x)$
\end{itemize}
%
To show that $(f,f_0) = (g,g_0)$, we need $p : f = g$ along with the
following square $p_0 x$ for every $x : F \alg{X}$:
$$
\xymatrix{
G\ f (\theta\ x) \ar@{-}[d]_{f_0 x} \ar@{-}[r]^{\ap\ (\lambda h . G\ h (\theta\ x)) p}  &G\ g\ (\theta\ x) \ar@{-}[d]^{g_0 x} \\
\rho\ (F\ f\ x) \ar@{-}[r]_{\ap\ (\lambda h . \rho\ (F\ h\ x)) p} &\rho\ (F\ g\ x) }
$$
\subsection{Identity laws}

Just as we have to assume that the functors $F$ and $G$ preserve
identity morphisms and composition to get that structure in the
category of dialgebras, we also need them to preserve the identity
\emph{laws} and associativity to show that the category of dialgebras
satisfies these laws. Let
$\leftid_{\C} : (f : \C(X,Y)) \to \Id{Y} \circ f = f$ be the witness
of the left identity law for $\C$. A functor $F : \C \to \Type$
preserves the left identity law, if for $f : \C (X,Y)$ and $x : FX$ we
have the following commuting diagram:
$$
\xymatrix{
F\ (\Id{Y} \circ f)\ x \ar@{-}[d]_{\Fcomp \Id{Y} f x} \ar@{-}[dr]^{\ap\ (\lambda h . F h x)\ \leftid_{\C}}\\
F\ \Id{Y}\ (F\ f\ x) \ar@{-}[r]_{\Fid (F\ f\ x)} &F\ f\ x
}
$$

To show that the left identity law holds for $\Alg_s$ given
$s : \Spec$, we proceed by induction on $s$. $\Type$ satisfies the left
identity law trivially, so the base case is done. For the inductive
case we get the following data:
%
\begin{itemize}
\item $\alg{X} : \Alg_s$
\item $\theta : F \alg{X} \to G \alg{X}$
\item $f : \Alg_s(\alg{X},\alg{Y})$ 
\item $f_0 : (x : F \alg{X}) \to G\ f\ (\theta\ x) = \rho\ (F\ f\ x)$
\item $\leftid_{\Alg_s} f : \Id{\alg{X}} \circ f = f$
\end{itemize}
%
We then need to show that $(h,h_0) = (f,f_0)$ where $h = \Id{\alg{X}} \circ f$ and
\begin{align*}
  &h_0 : (x : F \alg{X}) \to G\ (\Id{\alg{X}} \circ f)\ (\theta\ x) = \rho\ (F\ (\Id{\alg{X}} \circ f)\ x) \\
  &h_0\ x \defeq \\
  &\ \ \    \Gcomp\ \Id{\alg{Y}}\ f\ (\theta\ x) \\
  &\ \ct\ \ap\ (G\ \Id{\alg{Y}})\ (f_0\ x) \\
  &\ \ct\ \Gid_{\alg{Y}}\ (\rho\ x) \\
  &\ \ct\ \ap\ \rho\ (\Fid_{\alg{Y}}\ x)^{-1} \\
  &\ \ct\ \ap\ \rho\ (\Fcomp \Id{\alg{Y}}\ f\ x)^{-1}
\end{align*}

To show that $(h,h_0) = (f,f_0)$ we need to provide a $p : h = f$,
which is given by $\leftid_{\Alg_s} f$, and for every $x : F \alg{X}$ an equality:
$$
h_0\ x \ct \ap\ (\lambda h . \rho\ (F\ h\ x))\ \leftid_{\Alg_s} 
 = \ap\ (\lambda h . G\ h\ (\theta\ x))\ \leftid_{\Alg_s} \ct f_0\ x
$$
Unfolding the definition of $h_0\ x$, this equality can be given by
using the fact that $F$ and $G$ preserve the left identity law,
various properties of $\ap$ and the naturality property of
homotopies. Showing the right identity law can be done in a similar
way.

\subsection{Associativity}

Let
$\assoc_{\C} : (h : \C(Z,W)) (g : \C(Y,Z)) (f : \C(X,Y)) \to (h \circ
g) \circ f = h \circ (g \circ f)$
be the witness of associativity for $\C$. A functor $F : \C \to \Type$
preserves associativity if given morphisms:
$$
X \overset{f}\to Y \overset{g}\to Z \overset{h}\to W
$$
we have for any $x : FX$ the following pentagon:
$$
\xymatrix{
F\ ((h \circ g) \circ f)\ x 
  \ar@{-}[rr]^{\ap\ (\lambda h . F\ h\ x)\ (\assoc_{\C}\ h\ g\ f)} 
  \ar@{-}[d]_{\Fcomp\ (h \circ g)\ f\ x}
&&F\ (h \circ (g \circ f))\ x 
  \ar@{-}[d]^{\Fcomp\ h\ (g \circ f)\ x}
  \\
F\ (h \circ g)\ (F\ f\ x)
  \ar@{-}[dr]_{\Fcomp\ h\ g\ (F\ f\ x)}
&&F\ h\ (F\ (g \circ f)\ x) 
  \ar@{-}[dl]^{\ap\ (F\ h)\ (\Fcomp\ g\ f\ x)}
  \\
&F\ h\ (F\ g\ (F\ f\ x))&
}
$$
Assuming that our functors $F$ and $G$ satisfy this condition, we can
show that for any $s : \Spec$, $\Alg_s$ has associativity. Note that
the pentagon looks similar to the usual pentagonal coherence condition
for associators, in fact, if the functor is a representible functor,
the above diagram is such a pentagon.

\subsection{Products}

To show that the section principle is logically equivalent to
initiality, we saw in~\cref{sec:oitsectioninitiality} that we need to
have products and equalisers in our category. If we want to define
these in our categories of dialgebras, we have to make sure the target
functors $G$ preserve products and equalisers. For products, functors
$G : \C \to \Type$ need to be equipped with an operation
$\Gtimes : (X, Y : \C) \to GX \times_{\Type} GY \to G(X \times_{\C}
Y)$
relating the products of $\C$ with those of $\Type$. The operation
must commute with projections, \ie:
$$
\xymatrix{
GX \times_{\Type} GY 
 \ar[r]^{\Gtimes\ X\ Y} 
 \ar[rd]_{\pi_1}
&G(X \times_{\C} Y)
 \ar[d]^{G\ \pi_1} \\
&GX
}
$$
and an analogous diagram for $\pi_2$. Now we can define the product
for any category of dialgebras $\Alg_s$ given $s : \Spec$, by induction
on $s$:
%
\begin{itemize}
\item $\alg{X}, \alg{Y} : \Alg_s$
\item $\theta : F \alg{X} \to G \alg{X}$
\item $\rho : F \alg{Y} \to G \alg{Y}$
\end{itemize}
%
We define the dialgebra on $\alg{X} \times \alg{Y}$ as
\begin{align*}
&\theta \times \rho : F (\alg{X} \times \alg{Y}) \to G (\alg{X} \times \alg{Y}) \\
&\theta \times \rho\ x \ddefeq  \Gtimes\ (\theta\ (F\ \pi_1\ x))\ (\rho\ (F\ \pi_2\ x))
\end{align*}
Showing that $\pi_1$ and $\pi_2$ are algebra morphisms then uses the
commuting triangles introduced above.

\subsection{Equalisers}

Since equalisers in $\Type$ are very similar to products, constructing
equalisers in $Alg_s$ will be quite similar to the construction of
products in $Alg_s$. We will denote the equaliser in $\Type$ of
functions $f, g : X \to Y$ as $\eq_{\Type}\ f\ g$, which is defined as
$\eq_{\Type}\ f\ g \ddefeq (x : X) \times f\ x = g\ x$. Equalisers in
$\C$ will be denoted with $\eq_{\C}$. For equalisers, functors
$G : \C \to \Type$ need to be equipped with an operation
$\Geq : (f\ g : \C(X,Y)) \to \eq_{\Type}\ (G f)\ (G g) \to G (\eq_{\C}\
f\ g)$ such that the following commutes:
$$
\xymatrix{
\eq_{\Type}\ (G f)\ (G g)
 \ar[r]^{\Geq\ f\ g}
 \ar[rd]_{\pi_1}
&G (\eq_{\C}\ f\ g)
 \ar[d]^{G\ i} \\
&GX
}
$$
The carrier of the equaliser is then $\eq_{\C}\ f g$. By the universal
property of $\eq_{\Type}\ (G f)\ (G g)$ we have a function
$F (\eq_{\C}\ f\ g) \to \eq_{\Type}\ (G f)\ (G g)$, composing this
with $\Geq\ f\ g$ we get an algebra
$F (\eq_{\C}\ f\ g) \to G (\eq_{\C}\ f\ g)$.

\chapter{Generalised containers}
\label{sec:gencontainers}

So far we have not concerned ourselves with the existence of \hits and
as such have put no restrictions on the argument and target
functors. For \oits, we know that the argument functor has to
\emph{strictly positive} for the initial algebra to exist. For \hits a
more general notion of strict positivity is needed. Consider for
example the following type, which has as constructors the axioms of a
field:
%
\begin{alignat*}{2}
&\rlap{$\data\ \initialfield\ :\ \Type\ \where$} \\
&&\ \ 0        &:\ \initialfield \\
&&\ \ 1        &:\ \initialfield \\
&&\ \ +        &:\ \initialfield \to \initialfield \to \initialfield \\
&&\ \ *        &:\ \initialfield \to \initialfield \to \initialfield \\
&&&\vdots \\
&&\ \ ^{-1}     &:\ (x : \initialfield) \to (x = 0 \to \bot) \to \initialfield \\
&&&\vdots
\end{alignat*}
%
The type $\initialfield$ along with its constructors should give us
the initial object in the category of fields, but there is no such
object. The culprit here seems the constructor $^{-1}$, which has as
one of its arguments the type $x = 0 \to \bot$ where the constructor
$0 : \initialfield$ occurs negatively.

One way to generalise the notion of strict positivity is to generalise
the notion of containers:
%
\begin{defn}
  A \emph{generalised container} consists of a type of \emph{shapes}
  $S : \Type$ along with \emph{positions} $P : S \to \C$
\end{defn}
%
Instead of the positions being a family of types indexed by $S$, it is
now a family of objects of $\C$. The extension of a generalised
container is defined as:
%
\begin{align*}
  &\cext{S}{P}_0 : \C \to \Type \\
  &\cext{S}{P}_0 \ X \ddefeq (s : S) \times \C(P \ s,\ X)
\end{align*}
%
with the action on morphisms:
%
\begin{align*}
  &\cext{S}{P}_1 : \C(X , Y) \to \cext{S}{P}_0 \ X \to \cext{S}{P}_0 \ Y \\
  &\cext{S}{P}_1 \ f \ (s ,\ t) \ddefeq (s ,\ f \circ t)
\end{align*}
%
Showing that the action on morphisms preserves the category structure
is done by appealing to the category structure of $\C$. To show that
$\cext{S}{P}$ preserves the identity morphism, we get the following
proof:
%
\begin{align*}
&\cext{S}{P}_1 \ \Id{X} \ (s ,\ t) \\
&\defeq \\
&(s , \Id{X} \circ t) \\
&= \reasontext{left identity law of $\C$} \\
&(s, t)
\end{align*}
%
To show that $\cext{S}{P}$ preserves composition, we need to appeal to
associativity of $\C$. Recall that in order to show that extending a
category $\C$ with a constructor given by functors
$F, G : \C \to \Type$ has identity morphisms, we need $F$ and $G$ to
preserve identity morphisms. For generalised containers to preserve
identity morphisms, we need $\C$ to have the left identity law, a
coherence condition \emph{on} identity morphisms. Similarly, to show
that the category $\C$ extended with a constructor has composition, we
need associativity of $\C$. To show that it has associativity, we need
the associativity of $\C$ to satisfy the pentagon coherence law: for
every structure and coherence law in the extended category, we need
one level more in the original category. This means that the more
constructors we have in our specification, the more coherence laws we
need to show, if we use generalised containers.

To specify \hits using containers for the argument functors, we need
to deal with coherence in its full generality: we need to be able to
talk about \omegacats internally to type theory. One way to do this is
to internalise the notion of \emph{Segal category}, which in turn
depends on the notion of \emph{simplicial type}. To define simplicial
types, we need to have a way of talking about strict equalities in
type theory itself.

\section{Target functors}

The target functors are more restricted than just being strictly
positive: they either are a forgetful functor or an iterated path
space functor. In~\cref{sec:syntax} we have seen that these functors
are given via a sequence of natural transformations, with the first
ones $l, r : F \to U$ going from the arguments functor
$F : \C \to \Type$ into a forgetful functor $U : \C \to \Type$. If $U$
can be expressed as a container, we can give the natural
transformations as a \emph{container morphism}:

\begin{defn}
A container morphism $\cont{S}{P} \to \cont{T}{Q}$ is given by:
% 
\begin{itemize}
\item $\alpha_0 : S \to T$
\item $\alpha_1 : (s : S) \to \C(T\ (\alpha_0 s) ,\ P\ s)$
\end{itemize}
% 
\end{defn}

A container morphism
$(\alpha_0,\alpha_1) : \cont{S}{P} \to \cont{T}{Q}$ gives rise to the
following natural transformation:
%
\begin{align*}
  &\alpha : \{ X : | \C | \} \to \cext{S}{P} \ X \to \cext{T}{Q} \ X \\
  &\alpha\ (s , t) \ddefeq ( \alpha_0\ s ,\ t \circ \alpha_1\ s )
\end{align*}
%
Giving the naturality square of $\alpha$ is done by using
associativity of $\C$. Container morphisms on ordinary containers
therefore yield strict natural transformations. If we have given
natural transformations $l, r : F \to U$ as container morphisms, for
$F, U : \C \to \Type$, we still have to show that
$\lambda (X , x) . l_X x = g_X x : \int_{\C} F \to \Type$ is a functor
and satisfies the coherence conditions. Since naturality is given
using associativity of $\C$, the coherence properties of the functor
depend on those of $\C$.

Note that if $U : \C \to \Type$ has a left adjoint $L : \Type \to \C$,
it is in fact expressible as a container, as we have for any $X : \C$:
%
\begin{align*}
  U X &= 1 \to U X \\
      &= \C(L1, X)
\end{align*}
%
where $1 : \Type$ is the unit type. Hence we have that
$U = \cext{1}{L 1}$. We do not need any functorial properties of $L$:
we only need the object $L1 : \C$ that has the property shown
above. For the category $\algcat{F}$ for an endofunctor
$F : \Type \to \Type$, the left adjoint of the forgetful functor
$U : \algcat{F} \to \Type$ is defined using the free monad of $F$, as
we have seen in~\cref{sec:oitfreemonad}.

This means that in order for us to define $U : \algcat{F} \to \Type$
as a container, we need to have \oits available. Hence to specify \eg
a \hit with a \zeroconstructor followed by one \oneconstructor in this
way using containers and container morphisms, we also need to have
\oits available.

\chapter{Initiality and induction for \onehits}
\label{sec:onehits}

In~\cref{sec:hitscategory} we saw that we run into coherence issues
when describing the category structure in general. We can switch to
non-dependent dialgebras, which allows us to define the category of
dialgebras with enough categorical structure to do what we want to
do. In this section we consider a simplification of the general
scheme, which is expressive enough to include interesting
examples. Apart from this the coherence issues are still
manageable. We can restrict ourselves to \hits with a
\zeroconstructors followed by one \oneconstructor, \ie consider \hits
of the form:
%
\begin{alignat*}{2}
  &\rlap{$\data\ T\ :\ \Type\ \where$} \\
  &&\ \ c_0  &:\ F_0\ T \to T \\
  &&\ \ c_1  &:\ (x : F_1\ (T,c_0)) \to l_{(T,c_0)}\ x = r_{(T,c_0)}\ x
\end{alignat*}
%
where $l, r : F_1 \to U_0$, for $U_0 : \algcat{F_0} \to \Type$ the
forgetful functor. In~\cref{sec:hitscategory} we have seen that the
constructor $c_1$ is problematic if $F_1$ is not strict. If we $F_1$
is given as a generalised container, it will generally not be strict,
as it maps out of $\algcat{F}$, which in itself does not satisfy the
category laws strictly. To avoid this issue, we assume $F_1$ does not
use the algebra part $c_0$, \ie there exists $F_1' : \Type \to \Type$
such that $F_1 = F_1' \circ U_0$. With this restriction, the natural
transformations $F_1 \to U_0$ reduce to natural transformations
$F_1' \to F_0^*$: the target functors becomes
$G ((X,\theta_0), x) \ddefeq (\theta_0^*\ (l\ x) = \theta_0^*\ (r\
x))$,
where $\theta_0^* : F_0^* X \to X$ is the lifting of $\theta$ to the
free monad $F_0^*$. Now if $F_0, F_1 : \Type \to \Type$ are given as
containers, they will be strict functors, hence we avoid the coherence
issues mentioned in~\cref{sec:hitscategory}.

We arrive at the following form of \hits:
%
\begin{alignat*}{2}
  &\rlap{$\data\ T\ :\ \Type\ \where$} \\
  &&\ \ c_0  &:\ F_0\ T \to T \\
  &&\ \ c_1  &:\ (x : F_1\ T) \to c_0^*\ (l\ x) = c_0^*\ (r\ x)
\end{alignat*}
%
where:
\begin{itemize}
\item $F_0, F_1 : \Type \to \Type$ are functors, given as containers
\item $l, r : F_1 \to F_0^*$ are natural transformations, given as container morphisms
\end{itemize}

\section{Target functor}

For the inductive types we are talking about in this chapter there are
two target functors: one for the first constructor and one for the
second. Since the first target functor is just the identity functor,
it does not need any special treatment. As such, when we say ``the
target functor'', we are referring to the second target functor. This
target functor is defined as:
%
\begin{align*}
&G : \int_{\algcat{F_0}} (F_1 \circ U_0) \to \Type \\
&G\ ((X,\theta_0), x) \ddefeq (\theta_0^*\ (l_{X}\ x) = \theta_0^*\ (r_{X}\ x))
\end{align*}
%
with its action on morphisms:
%
\begin{align*}
&G : \int_{\algcat{F_0}} (F_1 \circ U_0) (((X,\theta_0),x),((Y,\rho_0),y)) \\
&\ \ \to G\ ((X,\theta_0),x) \to G\ ((Y,\rho_0),y) \\
&G\ ((f,f_0),p) q \ddefeq \\
&\ \ \rho_0^*\ (l\ y) \\
&\ \ = \reasonterm{\ap\ (\lambda z . \rho_0^*\ (l\ z))\ p} \\
&\ \ \rho_0^*\ (l\ (F_1\ f\ x)) \\
&\ \ \defeq \reasontext{naturality of $l$} \\
&\ \ \rho_0^*\ (F_0^*\ (l\ x)) \\
&\ \ = \reasonterm{f_0^*\ (l\ x)} \\
&\ \ f\ (\theta_0^*\ (l\ x)) \\
&\ \ = \reasonterm{\ap\ f\ q} \\
&\ \ f\ (\theta_0^*\ (r\ x)) \\
&\ \ = \reasonterm{f_0^*\ (r\ x)^{-1}} \\
&\ \ \rho_0^*\ (F_0^*\ f\ (r\ x)) \\
&\ \ \defeq \reasontext{naturality of $r$} \\
&\ \ \rho_0^*\ (r\ (F_1\ f\ x)) \\
&\ \ = \reasonterm{\ap\ (\lambda z . \rho_0^*\ (r\ z))\ p^{-1}} \\
&\ \ \rho_0^*\ (r\ y)
\end{align*}
%
The lifting $^* : \algcat{F_0} \to \algcat{F_0^*}$ is functorial, so
we also have a lifting of:
$$
f_0 : (x : F_0 X) \to f\ (\theta_0\ x) = \rho_0\ (F_0\ f\ x)
$$
to
$$
f_0^* : (x : F_0^* X) \to f\ (\theta_0^*\ x) = \rho_0^*\ (F_0^*\ f\ x)
$$

We can also show that the target functor preserves composition and
identity morphisms, appealing to functoriality of $\ap$ and of lifting
of algebras. This means that $G$ is not a strict functor.

\section{Category of algebras}

In~\cref{sec:hits} we have seen what the algebras and algebra
morphisms look like in the general case, so we can instantiate it for
our restricted version:
%
\begin{alignat*}{3}
&|\Alg_s| &&\ddefeq &&\ (X : Type) \\
&&&\ \times &&\ (\theta_0 : F_0 X \to X) \\
&&&\ \times &&\ (\theta_1 : (x : F_1 X) \to G\ ((X,\theta_0),x)
\end{alignat*}
%
with morphisms:
\begin{alignat*}{3}
  &\Alg_s((X,\theta_0,\theta_1),(Y,\rho_0,\rho_1)) &&\ddefeq &&\ (f : X \to Y) \\
  &&&\ \times &&\ (f_0 : (x : F_0 X) \to f\ (\theta_0\ x) = \rho_0\ (F_0\ f\ x)) \\
  &&&\ \times &&\ (f_1 : (x : F_1 X) \to G\ (\lift f) (\theta_1\ x) = \rho_1\ (F_1\ f\ x))
\end{alignat*}

Defining composition and identity morphisms is similar to what we have
done in~\cref{sec:nondepdialg}. Equality of algebra morphisms is a bit
more involved, since the second constructor is a \emph{dependent}
dialgebra.

\section{Induction principle}

\subsection{Algebra families}

\subsection{Dependent algebra morphisms}

\section{Limitations}

\chapter{Thesis outline}
\label{sec:outline}

\begin{itemize}
\item Introduction
\item Preliminaries
  \begin{itemize}
  \item \mltt
  \item \Hott
  \item Examples of \hits
  \item Category theory in type theory and \omegacat theory
  \item Generalised containers
  \end{itemize}
\item Syntax of \hits
\item Initiality and induction
  \begin{itemize}
  \item for \oits
  \item for \hits
  \end{itemize}
\item Properties of \hits
  \begin{itemize}
  \item Reordering of constructors
  \item Hub-spokes construction
  \item Flattening lemma
  \end{itemize}
\item Semantics of \hits
\item Future work
\end{itemize}

\bibliography{second-year-report}

\end{document}
